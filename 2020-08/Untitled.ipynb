{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://nifty-machine-learning-internship-2020/prefecture_area.csv to input/prefecture_area.csv\n",
      "download: s3://nifty-machine-learning-internship-2020/sample_submission.csv to input/sample_submission.csv\n",
      "download: s3://nifty-machine-learning-internship-2020/test.csv to input/test.csv\n",
      "download: s3://nifty-machine-learning-internship-2020/train.csv to input/train.csv\n",
      "download: s3://nifty-machine-learning-internship-2020/service_use_history.csv to input/service_use_history.csv\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp s3://nifty-machine-learning-internship-2020/ ./input --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history = pd.read_csv('input/service_use_history.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ユーザデータの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1560000 entries, 0 to 1559999\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count    Dtype \n",
      "---  ------   --------------    ----- \n",
      " 0   user_id  1560000 non-null  object\n",
      " 1   service  1560000 non-null  object\n",
      " 2   1        1560000 non-null  int64 \n",
      " 3   2        1560000 non-null  int64 \n",
      " 4   3        1560000 non-null  int64 \n",
      " 5   4        1560000 non-null  int64 \n",
      " 6   5        1560000 non-null  int64 \n",
      " 7   6        1560000 non-null  int64 \n",
      " 8   7        1560000 non-null  int64 \n",
      " 9   8        1560000 non-null  int64 \n",
      " 10  9        1560000 non-null  int64 \n",
      " 11  10       1560000 non-null  int64 \n",
      " 12  11       1560000 non-null  int64 \n",
      " 13  12       1560000 non-null  int64 \n",
      " 14  13       1560000 non-null  int64 \n",
      " 15  14       1560000 non-null  int64 \n",
      " 16  15       1560000 non-null  int64 \n",
      " 17  16       1560000 non-null  int64 \n",
      " 18  17       1560000 non-null  int64 \n",
      " 19  18       1560000 non-null  int64 \n",
      "dtypes: int64(18), object(2)\n",
      "memory usage: 238.0+ MB\n"
     ]
    }
   ],
   "source": [
    "user_history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>service</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SSEZIM80822</td>\n",
       "      <td>ニフティ会員特別でんきプラン</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SSEZIM80822</td>\n",
       "      <td>ニフティ会員特別ガスプラン</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SSEZIM80822</td>\n",
       "      <td>ココログ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SSEZIM80822</td>\n",
       "      <td>@niftyゲーム</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSEZIM80822</td>\n",
       "      <td>占い@nifty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id         service  1  2  3  4  5  6  7  8  9  10  11  12  13  14  \\\n",
       "0  SSEZIM80822  ニフティ会員特別でんきプラン  0  0  0  0  0  0  0  0  0   0   0   0   0   0   \n",
       "1  SSEZIM80822   ニフティ会員特別ガスプラン  0  0  0  0  0  0  0  0  0   0   0   0   0   0   \n",
       "2  SSEZIM80822            ココログ  0  0  0  0  0  0  0  0  0   0   0   0   0   0   \n",
       "3  SSEZIM80822       @niftyゲーム  0  0  1  1  1  1  1  1  1   1   1   1   1   1   \n",
       "4  SSEZIM80822        占い@nifty  0  0  0  0  0  0  0  0  0   0   0   0   0   0   \n",
       "\n",
       "   15  16  17  18  \n",
       "0   0   0   0   0  \n",
       "1   0   0   0   0  \n",
       "2   0   0   0   0  \n",
       "3   1   1   1   1  \n",
       "4   1   1   1   1  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(user_history, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "AAABGY38277    13\n",
       "AAACAO14849    13\n",
       "AAAEFM09396    13\n",
       "AAAKDN04796    13\n",
       "AAAVIU66062    13\n",
       "               ..\n",
       "ZZZAZC59621    13\n",
       "ZZZBJS33949    13\n",
       "ZZZHTV57785    13\n",
       "ZZZOLR31128    13\n",
       "ZZZTCL58697    13\n",
       "Name: service, Length: 100000, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.groupby('user_id').count()['service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "ZZZTCL58697    13\n",
       "IQQTAZ84183    13\n",
       "IQMDOQ33602    13\n",
       "IQMKKJ02602    13\n",
       "IQMLVE93988    13\n",
       "               ..\n",
       "RJDNTZ51771    13\n",
       "RJDONK25765    13\n",
       "RJDYLG37123    13\n",
       "RJEKRH45569    13\n",
       "AAABGY38277    13\n",
       "Name: service, Length: 100000, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.groupby('user_id').count()['service'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各ユーザは、１３個のプランに申し込んでいる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_columns= []\n",
    "for i in range(1, 19):\n",
    "    month_columns.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299997</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18\n",
       "0        0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0\n",
       "1        0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0\n",
       "2        0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0\n",
       "3        0  0  1  1  1  1  1  1  1   1   1   1   1   1   1   1   1   1\n",
       "4        0  0  0  0  0  0  0  0  0   0   0   0   0   0   1   1   1   1\n",
       "...     .. .. .. .. .. .. .. .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "1299995  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0\n",
       "1299996  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   1   1   1\n",
       "1299997  1  1  1  1  1  1  1  1  1   1   1   1   1   1   1   1   1   1\n",
       "1299998  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0\n",
       "1299999  0  0  0  0  0  0  0  0  0   1   1   1   1   1   1   0   0   0\n",
       "\n",
       "[1300000 rows x 18 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df[month_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_count_values = merge_df.sum(axis=1)\n",
    "df_concat = pd.concat([merge_df, y_count_values], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_count_values_no = y_count_values[df_concat['close_flag']==0]\n",
    "y_count_values_yes = y_count_values[df_concat['close_flag']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[644854.,  34743.,  34213.,  65172.,  16029.,  12836.,  28912.,\n",
       "          18832.,  20462., 294103.],\n",
       "        [ 74839.,   4629.,   4319.,   8212.,   2888.,   1511.,   2899.,\n",
       "           1720.,   2056.,  26771.]]),\n",
       " array([ 0. ,  1.9,  3.8,  5.7,  7.6,  9.5, 11.4, 13.3, 15.2, 17.1, 19. ]),\n",
       " <a list of 2 Lists of Patches objects>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([y_count_values_no, y_count_values_yes], label=['継続日数のカウント数', '目的変数'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>id_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>pay_method_type</th>\n",
       "      <th>course_name</th>\n",
       "      <th>price_type</th>\n",
       "      <th>entry_from</th>\n",
       "      <th>privilege_name</th>\n",
       "      <th>prefecture</th>\n",
       "      <th>close_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YKJGBC19356</td>\n",
       "      <td>新規</td>\n",
       "      <td>男性</td>\n",
       "      <td>A</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty光</td>\n",
       "      <td>マンション2年プラン</td>\n",
       "      <td>代理店取次</td>\n",
       "      <td>キャッシュバック還元</td>\n",
       "      <td>鹿児島</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JMFEBB08712</td>\n",
       "      <td>新規</td>\n",
       "      <td>女性</td>\n",
       "      <td>O</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty光</td>\n",
       "      <td>ホーム2年プラン</td>\n",
       "      <td>代理店取次</td>\n",
       "      <td>付帯サービス無料</td>\n",
       "      <td>北海道</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXLFTB26665</td>\n",
       "      <td>既存</td>\n",
       "      <td>女性</td>\n",
       "      <td>AB</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty auひかり</td>\n",
       "      <td>ホーム2年プラン</td>\n",
       "      <td>ノジマ取次</td>\n",
       "      <td>月額割引還元</td>\n",
       "      <td>長野</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MWEEMY19722</td>\n",
       "      <td>新規</td>\n",
       "      <td>男性</td>\n",
       "      <td>B</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty光</td>\n",
       "      <td>マンション2年プラン</td>\n",
       "      <td>代理店取次</td>\n",
       "      <td>キャッシュバック還元</td>\n",
       "      <td>福島</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WWTLYT31226</td>\n",
       "      <td>新規</td>\n",
       "      <td>男性</td>\n",
       "      <td>A</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty auひかり</td>\n",
       "      <td>マンション3年プラン</td>\n",
       "      <td>WEB代理店</td>\n",
       "      <td>付帯サービス無料</td>\n",
       "      <td>愛知</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id id_status gender blood_type pay_method_type   course_name  \\\n",
       "0  YKJGBC19356        新規     男性          A        クレジットカード       @nifty光   \n",
       "1  JMFEBB08712        新規     女性          O        クレジットカード       @nifty光   \n",
       "2  EXLFTB26665        既存     女性         AB        クレジットカード  @nifty auひかり   \n",
       "3  MWEEMY19722        新規     男性          B        クレジットカード       @nifty光   \n",
       "4  WWTLYT31226        新規     男性          A        クレジットカード  @nifty auひかり   \n",
       "\n",
       "   price_type entry_from privilege_name prefecture  close_flag  \n",
       "0  マンション2年プラン      代理店取次     キャッシュバック還元        鹿児島           0  \n",
       "1    ホーム2年プラン      代理店取次       付帯サービス無料        北海道           0  \n",
       "2    ホーム2年プラン      ノジマ取次         月額割引還元         長野           0  \n",
       "3  マンション2年プラン      代理店取次     キャッシュバック還元         福島           0  \n",
       "4  マンション3年プラン     WEB代理店       付帯サービス無料         愛知           0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime_columns = ['entry_date', 'open_date', 'birthday']\n",
    "for column in datetime_columns:\n",
    "    train = train.drop(column, axis=1)\n",
    "\n",
    "train = train.drop('user_agent', axis=1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>pay_method_type</th>\n",
       "      <th>course_name</th>\n",
       "      <th>price_type</th>\n",
       "      <th>entry_from</th>\n",
       "      <th>privilege_name</th>\n",
       "      <th>prefecture</th>\n",
       "      <th>close_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YKJGBC19356</th>\n",
       "      <td>新規</td>\n",
       "      <td>男性</td>\n",
       "      <td>A</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty光</td>\n",
       "      <td>マンション2年プラン</td>\n",
       "      <td>代理店取次</td>\n",
       "      <td>キャッシュバック還元</td>\n",
       "      <td>鹿児島</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JMFEBB08712</th>\n",
       "      <td>新規</td>\n",
       "      <td>女性</td>\n",
       "      <td>O</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty光</td>\n",
       "      <td>ホーム2年プラン</td>\n",
       "      <td>代理店取次</td>\n",
       "      <td>付帯サービス無料</td>\n",
       "      <td>北海道</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXLFTB26665</th>\n",
       "      <td>既存</td>\n",
       "      <td>女性</td>\n",
       "      <td>AB</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty auひかり</td>\n",
       "      <td>ホーム2年プラン</td>\n",
       "      <td>ノジマ取次</td>\n",
       "      <td>月額割引還元</td>\n",
       "      <td>長野</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MWEEMY19722</th>\n",
       "      <td>新規</td>\n",
       "      <td>男性</td>\n",
       "      <td>B</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty光</td>\n",
       "      <td>マンション2年プラン</td>\n",
       "      <td>代理店取次</td>\n",
       "      <td>キャッシュバック還元</td>\n",
       "      <td>福島</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WWTLYT31226</th>\n",
       "      <td>新規</td>\n",
       "      <td>男性</td>\n",
       "      <td>A</td>\n",
       "      <td>クレジットカード</td>\n",
       "      <td>@nifty auひかり</td>\n",
       "      <td>マンション3年プラン</td>\n",
       "      <td>WEB代理店</td>\n",
       "      <td>付帯サービス無料</td>\n",
       "      <td>愛知</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_status gender blood_type pay_method_type   course_name  \\\n",
       "user_id                                                                 \n",
       "YKJGBC19356        新規     男性          A        クレジットカード       @nifty光   \n",
       "JMFEBB08712        新規     女性          O        クレジットカード       @nifty光   \n",
       "EXLFTB26665        既存     女性         AB        クレジットカード  @nifty auひかり   \n",
       "MWEEMY19722        新規     男性          B        クレジットカード       @nifty光   \n",
       "WWTLYT31226        新規     男性          A        クレジットカード  @nifty auひかり   \n",
       "\n",
       "             price_type entry_from privilege_name prefecture  close_flag  \n",
       "user_id                                                                   \n",
       "YKJGBC19356  マンション2年プラン      代理店取次     キャッシュバック還元        鹿児島           0  \n",
       "JMFEBB08712    ホーム2年プラン      代理店取次       付帯サービス無料        北海道           0  \n",
       "EXLFTB26665    ホーム2年プラン      ノジマ取次         月額割引還元         長野           0  \n",
       "MWEEMY19722  マンション2年プラン      代理店取次     キャッシュバック還元         福島           0  \n",
       "WWTLYT31226  マンション3年プラン     WEB代理店       付帯サービス無料         愛知           0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.set_index('user_id')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns = ['id_status', 'gender', 'blood_type', 'pay_method_type', 'course_name', 'price_type', 'entry_from', 'privilege_name', 'prefecture']\n",
    "\n",
    "encoders = {}\n",
    "for column in category_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[column])\n",
    "    train[column] = le.transform(train[column])\n",
    "    encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_mean_period=df_concat.groupby('user_id', as_index=False).mean().iloc[:, [0,-1]]\n",
    "customer_mean_period = customer_mean_period.rename(columns={0: 'customer_period'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('input/train.csv')\n",
    "train_data = pd.merge(train_data, customer_mean_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_columns = ['entry_date', 'open_date', 'birthday']\n",
    "for column in datetime_columns:\n",
    "    train_data = train_data.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('user_agent', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>id_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>pay_method_type</th>\n",
       "      <th>course_name</th>\n",
       "      <th>price_type</th>\n",
       "      <th>entry_from</th>\n",
       "      <th>privilege_name</th>\n",
       "      <th>prefecture</th>\n",
       "      <th>close_flag</th>\n",
       "      <th>customer_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YKJGBC19356</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>5.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JMFEBB08712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXLFTB26665</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>7.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MWEEMY19722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>5.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WWTLYT31226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>8.769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  id_status  gender  blood_type  pay_method_type  course_name  \\\n",
       "0  YKJGBC19356          0       1           0                1            2   \n",
       "1  JMFEBB08712          0       0           3                1            2   \n",
       "2  EXLFTB26665          1       0           1                1            0   \n",
       "3  MWEEMY19722          0       1           2                1            2   \n",
       "4  WWTLYT31226          0       1           0                1            0   \n",
       "\n",
       "   price_type  entry_from  privilege_name  prefecture  close_flag  \\\n",
       "0           2           3               0          47           0   \n",
       "1           0           3               1           5           0   \n",
       "2           0           2               2          41           0   \n",
       "3           2           3               0          36           0   \n",
       "4           3           0               1          25           0   \n",
       "\n",
       "   customer_period  \n",
       "0         5.307692  \n",
       "1         5.923077  \n",
       "2         7.692308  \n",
       "3         5.307692  \n",
       "4         8.769231  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_columns = ['id_status', 'gender', 'blood_type', 'pay_method_type', 'course_name', 'price_type', 'entry_from', 'privilege_name', 'prefecture']\n",
    "\n",
    "encoders = {}\n",
    "for column in category_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data[column])\n",
    "    train_data[column] = le.transform(train_data[column])\n",
    "    encoders[column] = le\n",
    "    \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 10) (10000, 10) (90000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = train_data.set_index('user_id')\n",
    "y = train_data['close_flag']\n",
    "X = train_data.drop('close_flag', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =GradientBoostingClassifier(\n",
    "    min_samples_split = 5, \n",
    "    min_samples_leaf = 50, \n",
    "    max_depth = 5, \n",
    "    max_features = 'sqrt', \n",
    "    subsample = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5, max_features='sqrt',\n",
       "                           min_samples_leaf=50, min_samples_split=5,\n",
       "                           subsample=0.8)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9052\n",
      "roc_auc_score: 0.7488785493473247\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train )\n",
    "y_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "y_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "print(f'accuracy_score: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'roc_auc_score: {roc_auc_score(y_test, y_pred_prob)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge_df = pd.merge(user_history, test)\n",
    "test_y_count_values = test_merge_df.sum(axis=1)\n",
    "df_concat = pd.concat([test_merge_df, test_y_count_values], axis=1)\n",
    "customer_mean_period=df_concat.groupby('user_id', as_index=False).mean().iloc[:, [0,-1]]\n",
    "customer_mean_period = customer_mean_period.rename(columns={0: 'customer_period'})\n",
    "test = pd.merge(test, customer_mean_period)\n",
    "\n",
    "test = test.set_index('user_id')\n",
    "\n",
    "datetime_columns = ['entry_date', 'open_date', 'birthday']\n",
    "for column in datetime_columns:\n",
    "    test = test.drop(column, axis=1)\n",
    "test = test.drop('user_agent', axis=1)\n",
    "\n",
    "category_columns = ['id_status', 'gender', 'blood_type', 'pay_method_type', 'course_name', 'price_type', 'entry_from', 'privilege_name', 'prefecture']\n",
    "for column in category_columns:\n",
    "    le = encoders[column]\n",
    "    le.fit(test[column])\n",
    "    test[column] = le.transform(test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>close_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HLSZTB50403</td>\n",
       "      <td>0.167944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FCQNUE35187</td>\n",
       "      <td>0.126464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IYSBZQ82404</td>\n",
       "      <td>0.141738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPIREY57201</td>\n",
       "      <td>0.143703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISWWBF46615</td>\n",
       "      <td>0.071985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  close_flag\n",
       "0  HLSZTB50403    0.167944\n",
       "1  FCQNUE35187    0.126464\n",
       "2  IYSBZQ82404    0.141738\n",
       "3  BPIREY57201    0.143703\n",
       "4  ISWWBF46615    0.071985"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'user_id': test.index, 'close_flag': clf.predict_proba(test)[:,1]})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output/submit3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from xgboost) (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from xgboost) (1.18.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def model_validation(train_x, train_y, test):\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "    for tr_idx, va_idx in kf.split(train_x):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y[tr_idx], train_y[va_idx]\n",
    "        clf_xgb = xgb.XGBClassifier()\n",
    "        clf_xgb.fit(tr_x, tr_y,\n",
    "            eval_set=[(va_x, va_y)])\n",
    "        va_pred  = clf_xgb.predict(va_x)\n",
    "\n",
    "        print(f'roc_auc_score: {roc_auc_score(va_y, va_pred)}')\n",
    "        score = roc_auc_score(va_y, va_pred)\n",
    "        scores.append(score)\n",
    "    print(np.mean(scores))\n",
    "    return clf_xgb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling_func(X,num,label) :\n",
    "\n",
    "    # KMeansによるクラスタリング\n",
    "    from sklearn.cluster import KMeans\n",
    "    km = KMeans(random_state=201707)\n",
    "    km.fit(X,Y)\n",
    "    X['Cluster'] = km.predict(X)\n",
    "\n",
    "    # 群別の構成比を少数派の件数に乗じて群別の抽出件数を計算\n",
    "    count_sum = X.groupby('Cluster').count().iloc[0:,0].as_matrix()\n",
    "    ratio = count_sum / count_sum.sum()\n",
    "    samp_num = np.round(ratio * num,0).astype(np.int32)\n",
    "\n",
    "    # 群別にサンプリング処理を実施\n",
    "    for i in np.arange(8) :\n",
    "        tmp = X[X['Cluster']==i]\n",
    "        if i == 0 :\n",
    "            tmp1 = X.sample(samp_num[i],replace=True)\n",
    "        else :\n",
    "            tmp2 = X.sample(samp_num[i],replace=True)\n",
    "            tmp1 = pd.concat([tmp1,tmp2])\n",
    "    tmp1['Class'] = label\n",
    "    return tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampling = pd.read_csv('input/train.csv')\n",
    "test_sampling = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([90012.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,  9988.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_sampling['close_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "flug1_count = train_sampling[train_sampling['close_flag']==1]['close_flag'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90012"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampling[train_sampling['close_flag']==0]['close_flag'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39617   855 47187 ... 66600 19738 82188]\n"
     ]
    }
   ],
   "source": [
    "# X=train_sampling.drop('close_flag', axis=1)\n",
    "X = train_sampling.drop('close_flag', axis=1)\n",
    "y = train_sampling['close_flag']\n",
    "datetime_columns = ['entry_date', 'open_date', 'birthday']\n",
    "for column in datetime_columns:\n",
    "    X = X.drop(column, axis=1)\n",
    "X = X.drop('user_agent', axis=1)\n",
    "X = X.drop('user_id', axis=1)\n",
    "category_columns = ['id_status', 'gender', 'blood_type', 'pay_method_type', 'course_name', 'price_type', 'entry_from', 'privilege_name', 'prefecture']\n",
    "for column in category_columns:\n",
    "    le = encoders[column]\n",
    "    le.fit(X[column])\n",
    "    X[column] = le.transform(X[column])\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def imbalanced_data_split(X, y, test_size=0.2):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        print(train_index)\n",
    "        X_train, X_test = X.loc[train_index, :], X.loc[test_index, :]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = imbalanced_data_split(X, y, test_size=0.2)\n",
    "# for validation\n",
    "X_train2, X_valid, y_train2, y_valid = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.0.0-py2.py3-none-manylinux1_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn!=0.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from lightgbm) (0.23.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from lightgbm) (1.18.5)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from lightgbm) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lgbm_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 8,\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'reg_alpha' : 1,\n",
    "    'reg_lambda' : 1,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "}\n",
    "\n",
    "def lgbm_train(X_train_df, X_valid_df, y_train_df, y_valid_df, lgbm_params):\n",
    "    lgb_train = lgb.Dataset(X_train_df, y_train_df)\n",
    "    lgb_eval = lgb.Dataset(X_valid_df, y_valid_df, reference=lgb_train)\n",
    "\n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = lgb.train(lgbm_params, lgb_train,\n",
    "                      # モデルの評価用データを渡す\n",
    "                      valid_sets=lgb_eval,\n",
    "                      # 最大で 1000 ラウンドまで学習する\n",
    "                      num_boost_round=1000,\n",
    "                      # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "                      early_stopping_rounds=10)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6379, number of negative: 57621\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 64000, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099672 -> initscore=-2.200876\n",
      "[LightGBM] [Info] Start training from score -2.200876\n",
      "[1]\tvalid_0's auc: 0.618749\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.653952\n",
      "[3]\tvalid_0's auc: 0.679468\n",
      "[4]\tvalid_0's auc: 0.680412\n",
      "[5]\tvalid_0's auc: 0.680509\n",
      "[6]\tvalid_0's auc: 0.68501\n",
      "[7]\tvalid_0's auc: 0.687231\n",
      "[8]\tvalid_0's auc: 0.688249\n",
      "[9]\tvalid_0's auc: 0.694383\n",
      "[10]\tvalid_0's auc: 0.698989\n",
      "[11]\tvalid_0's auc: 0.70137\n",
      "[12]\tvalid_0's auc: 0.701873\n",
      "[13]\tvalid_0's auc: 0.704847\n",
      "[14]\tvalid_0's auc: 0.704387\n",
      "[15]\tvalid_0's auc: 0.704471\n",
      "[16]\tvalid_0's auc: 0.70826\n",
      "[17]\tvalid_0's auc: 0.710187\n",
      "[18]\tvalid_0's auc: 0.710697\n",
      "[19]\tvalid_0's auc: 0.711486\n",
      "[20]\tvalid_0's auc: 0.715004\n",
      "[21]\tvalid_0's auc: 0.714403\n",
      "[22]\tvalid_0's auc: 0.716081\n",
      "[23]\tvalid_0's auc: 0.716874\n",
      "[24]\tvalid_0's auc: 0.717161\n",
      "[25]\tvalid_0's auc: 0.71882\n",
      "[26]\tvalid_0's auc: 0.719914\n",
      "[27]\tvalid_0's auc: 0.72024\n",
      "[28]\tvalid_0's auc: 0.720063\n",
      "[29]\tvalid_0's auc: 0.720805\n",
      "[30]\tvalid_0's auc: 0.720517\n",
      "[31]\tvalid_0's auc: 0.721223\n",
      "[32]\tvalid_0's auc: 0.7228\n",
      "[33]\tvalid_0's auc: 0.723655\n",
      "[34]\tvalid_0's auc: 0.724238\n",
      "[35]\tvalid_0's auc: 0.725008\n",
      "[36]\tvalid_0's auc: 0.725009\n",
      "[37]\tvalid_0's auc: 0.725363\n",
      "[38]\tvalid_0's auc: 0.72641\n",
      "[39]\tvalid_0's auc: 0.726232\n",
      "[40]\tvalid_0's auc: 0.726368\n",
      "[41]\tvalid_0's auc: 0.726481\n",
      "[42]\tvalid_0's auc: 0.726773\n",
      "[43]\tvalid_0's auc: 0.727538\n",
      "[44]\tvalid_0's auc: 0.727189\n",
      "[45]\tvalid_0's auc: 0.727742\n",
      "[46]\tvalid_0's auc: 0.728097\n",
      "[47]\tvalid_0's auc: 0.728754\n",
      "[48]\tvalid_0's auc: 0.728805\n",
      "[49]\tvalid_0's auc: 0.729026\n",
      "[50]\tvalid_0's auc: 0.729379\n",
      "[51]\tvalid_0's auc: 0.729148\n",
      "[52]\tvalid_0's auc: 0.729541\n",
      "[53]\tvalid_0's auc: 0.730139\n",
      "[54]\tvalid_0's auc: 0.730267\n",
      "[55]\tvalid_0's auc: 0.730635\n",
      "[56]\tvalid_0's auc: 0.730935\n",
      "[57]\tvalid_0's auc: 0.731064\n",
      "[58]\tvalid_0's auc: 0.731316\n",
      "[59]\tvalid_0's auc: 0.731944\n",
      "[60]\tvalid_0's auc: 0.732084\n",
      "[61]\tvalid_0's auc: 0.732043\n",
      "[62]\tvalid_0's auc: 0.73261\n",
      "[63]\tvalid_0's auc: 0.733054\n",
      "[64]\tvalid_0's auc: 0.733446\n",
      "[65]\tvalid_0's auc: 0.733412\n",
      "[66]\tvalid_0's auc: 0.733559\n",
      "[67]\tvalid_0's auc: 0.733877\n",
      "[68]\tvalid_0's auc: 0.734065\n",
      "[69]\tvalid_0's auc: 0.734517\n",
      "[70]\tvalid_0's auc: 0.735078\n",
      "[71]\tvalid_0's auc: 0.73515\n",
      "[72]\tvalid_0's auc: 0.735142\n",
      "[73]\tvalid_0's auc: 0.735174\n",
      "[74]\tvalid_0's auc: 0.735436\n",
      "[75]\tvalid_0's auc: 0.735485\n",
      "[76]\tvalid_0's auc: 0.735448\n",
      "[77]\tvalid_0's auc: 0.735752\n",
      "[78]\tvalid_0's auc: 0.735729\n",
      "[79]\tvalid_0's auc: 0.735821\n",
      "[80]\tvalid_0's auc: 0.736018\n",
      "[81]\tvalid_0's auc: 0.736214\n",
      "[82]\tvalid_0's auc: 0.736473\n",
      "[83]\tvalid_0's auc: 0.736435\n",
      "[84]\tvalid_0's auc: 0.736472\n",
      "[85]\tvalid_0's auc: 0.736668\n",
      "[86]\tvalid_0's auc: 0.73672\n",
      "[87]\tvalid_0's auc: 0.73684\n",
      "[88]\tvalid_0's auc: 0.736971\n",
      "[89]\tvalid_0's auc: 0.736971\n",
      "[90]\tvalid_0's auc: 0.73745\n",
      "[91]\tvalid_0's auc: 0.737458\n",
      "[92]\tvalid_0's auc: 0.737674\n",
      "[93]\tvalid_0's auc: 0.737779\n",
      "[94]\tvalid_0's auc: 0.737995\n",
      "[95]\tvalid_0's auc: 0.737995\n",
      "[96]\tvalid_0's auc: 0.737967\n",
      "[97]\tvalid_0's auc: 0.738002\n",
      "[98]\tvalid_0's auc: 0.737999\n",
      "[99]\tvalid_0's auc: 0.738392\n",
      "[100]\tvalid_0's auc: 0.738391\n",
      "[101]\tvalid_0's auc: 0.738359\n",
      "[102]\tvalid_0's auc: 0.738792\n",
      "[103]\tvalid_0's auc: 0.738817\n",
      "[104]\tvalid_0's auc: 0.739027\n",
      "[105]\tvalid_0's auc: 0.739282\n",
      "[106]\tvalid_0's auc: 0.739337\n",
      "[107]\tvalid_0's auc: 0.739443\n",
      "[108]\tvalid_0's auc: 0.739434\n",
      "[109]\tvalid_0's auc: 0.739368\n",
      "[110]\tvalid_0's auc: 0.739348\n",
      "[111]\tvalid_0's auc: 0.73935\n",
      "[112]\tvalid_0's auc: 0.739317\n",
      "[113]\tvalid_0's auc: 0.739436\n",
      "[114]\tvalid_0's auc: 0.739542\n",
      "[115]\tvalid_0's auc: 0.739599\n",
      "[116]\tvalid_0's auc: 0.739784\n",
      "[117]\tvalid_0's auc: 0.739888\n",
      "[118]\tvalid_0's auc: 0.73991\n",
      "[119]\tvalid_0's auc: 0.739957\n",
      "[120]\tvalid_0's auc: 0.740035\n",
      "[121]\tvalid_0's auc: 0.74015\n",
      "[122]\tvalid_0's auc: 0.740158\n",
      "[123]\tvalid_0's auc: 0.740163\n",
      "[124]\tvalid_0's auc: 0.740126\n",
      "[125]\tvalid_0's auc: 0.740238\n",
      "[126]\tvalid_0's auc: 0.740334\n",
      "[127]\tvalid_0's auc: 0.740352\n",
      "[128]\tvalid_0's auc: 0.740289\n",
      "[129]\tvalid_0's auc: 0.7403\n",
      "[130]\tvalid_0's auc: 0.740402\n",
      "[131]\tvalid_0's auc: 0.74048\n",
      "[132]\tvalid_0's auc: 0.740514\n",
      "[133]\tvalid_0's auc: 0.740598\n",
      "[134]\tvalid_0's auc: 0.740712\n",
      "[135]\tvalid_0's auc: 0.74073\n",
      "[136]\tvalid_0's auc: 0.740667\n",
      "[137]\tvalid_0's auc: 0.740831\n",
      "[138]\tvalid_0's auc: 0.740967\n",
      "[139]\tvalid_0's auc: 0.740972\n",
      "[140]\tvalid_0's auc: 0.741037\n",
      "[141]\tvalid_0's auc: 0.741293\n",
      "[142]\tvalid_0's auc: 0.741245\n",
      "[143]\tvalid_0's auc: 0.741183\n",
      "[144]\tvalid_0's auc: 0.741248\n",
      "[145]\tvalid_0's auc: 0.741261\n",
      "[146]\tvalid_0's auc: 0.741291\n",
      "[147]\tvalid_0's auc: 0.741288\n",
      "[148]\tvalid_0's auc: 0.741397\n",
      "[149]\tvalid_0's auc: 0.741287\n",
      "[150]\tvalid_0's auc: 0.741262\n",
      "[151]\tvalid_0's auc: 0.741206\n",
      "[152]\tvalid_0's auc: 0.741333\n",
      "[153]\tvalid_0's auc: 0.741364\n",
      "[154]\tvalid_0's auc: 0.74135\n",
      "[155]\tvalid_0's auc: 0.74141\n",
      "[156]\tvalid_0's auc: 0.741397\n",
      "[157]\tvalid_0's auc: 0.741403\n",
      "[158]\tvalid_0's auc: 0.741364\n",
      "[159]\tvalid_0's auc: 0.741452\n",
      "[160]\tvalid_0's auc: 0.741505\n",
      "[161]\tvalid_0's auc: 0.741531\n",
      "[162]\tvalid_0's auc: 0.741515\n",
      "[163]\tvalid_0's auc: 0.741538\n",
      "[164]\tvalid_0's auc: 0.741466\n",
      "[165]\tvalid_0's auc: 0.741502\n",
      "[166]\tvalid_0's auc: 0.741486\n",
      "[167]\tvalid_0's auc: 0.741496\n",
      "[168]\tvalid_0's auc: 0.74151\n",
      "[169]\tvalid_0's auc: 0.741486\n",
      "[170]\tvalid_0's auc: 0.741402\n",
      "[171]\tvalid_0's auc: 0.741372\n",
      "[172]\tvalid_0's auc: 0.741469\n",
      "[173]\tvalid_0's auc: 0.741457\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's auc: 0.741538\n",
      "0.7279800075600542\n"
     ]
    }
   ],
   "source": [
    "model_normal = lgbm_train(X_train2, X_valid, y_train2, y_valid, lgbm_params)\n",
    "y_pred_normal = model_normal.predict(X_test, num_iteration=model_normal.best_iteration)\n",
    "\n",
    "# auc を計算する\n",
    "auc = roc_auc_score(y_test, y_pred_normal)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.7.0 imblearn-0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "# downsampling\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "# for validation\n",
    "X_train2, X_valid, y_train2, y_valid = imbalanced_data_split(X_resampled, y_resampled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7990.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        7990.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.606076\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.607081\n",
      "[3]\tvalid_0's auc: 0.658011\n",
      "[4]\tvalid_0's auc: 0.659639\n",
      "[5]\tvalid_0's auc: 0.6605\n",
      "[6]\tvalid_0's auc: 0.677231\n",
      "[7]\tvalid_0's auc: 0.683277\n",
      "[8]\tvalid_0's auc: 0.683617\n",
      "[9]\tvalid_0's auc: 0.692754\n",
      "[10]\tvalid_0's auc: 0.702581\n",
      "[11]\tvalid_0's auc: 0.702467\n",
      "[12]\tvalid_0's auc: 0.703218\n",
      "[13]\tvalid_0's auc: 0.709062\n",
      "[14]\tvalid_0's auc: 0.715464\n",
      "[15]\tvalid_0's auc: 0.714837\n",
      "[16]\tvalid_0's auc: 0.718766\n",
      "[17]\tvalid_0's auc: 0.719368\n",
      "[18]\tvalid_0's auc: 0.718885\n",
      "[19]\tvalid_0's auc: 0.720746\n",
      "[20]\tvalid_0's auc: 0.722836\n",
      "[21]\tvalid_0's auc: 0.723181\n",
      "[22]\tvalid_0's auc: 0.722905\n",
      "[23]\tvalid_0's auc: 0.724813\n",
      "[24]\tvalid_0's auc: 0.724082\n",
      "[25]\tvalid_0's auc: 0.726025\n",
      "[26]\tvalid_0's auc: 0.725527\n",
      "[27]\tvalid_0's auc: 0.724328\n",
      "[28]\tvalid_0's auc: 0.726795\n",
      "[29]\tvalid_0's auc: 0.727963\n",
      "[30]\tvalid_0's auc: 0.728073\n",
      "[31]\tvalid_0's auc: 0.727387\n",
      "[32]\tvalid_0's auc: 0.728047\n",
      "[33]\tvalid_0's auc: 0.72889\n",
      "[34]\tvalid_0's auc: 0.729209\n",
      "[35]\tvalid_0's auc: 0.728559\n",
      "[36]\tvalid_0's auc: 0.72982\n",
      "[37]\tvalid_0's auc: 0.730483\n",
      "[38]\tvalid_0's auc: 0.730623\n",
      "[39]\tvalid_0's auc: 0.731442\n",
      "[40]\tvalid_0's auc: 0.731107\n",
      "[41]\tvalid_0's auc: 0.731842\n",
      "[42]\tvalid_0's auc: 0.732913\n",
      "[43]\tvalid_0's auc: 0.732461\n",
      "[44]\tvalid_0's auc: 0.732233\n",
      "[45]\tvalid_0's auc: 0.732954\n",
      "[46]\tvalid_0's auc: 0.733758\n",
      "[47]\tvalid_0's auc: 0.733952\n",
      "[48]\tvalid_0's auc: 0.733913\n",
      "[49]\tvalid_0's auc: 0.733503\n",
      "[50]\tvalid_0's auc: 0.733336\n",
      "[51]\tvalid_0's auc: 0.733478\n",
      "[52]\tvalid_0's auc: 0.734835\n",
      "[53]\tvalid_0's auc: 0.734694\n",
      "[54]\tvalid_0's auc: 0.734537\n",
      "[55]\tvalid_0's auc: 0.735161\n",
      "[56]\tvalid_0's auc: 0.735521\n",
      "[57]\tvalid_0's auc: 0.735701\n",
      "[58]\tvalid_0's auc: 0.736352\n",
      "[59]\tvalid_0's auc: 0.736839\n",
      "[60]\tvalid_0's auc: 0.737183\n",
      "[61]\tvalid_0's auc: 0.736888\n",
      "[62]\tvalid_0's auc: 0.736986\n",
      "[63]\tvalid_0's auc: 0.736762\n",
      "[64]\tvalid_0's auc: 0.737272\n",
      "[65]\tvalid_0's auc: 0.737051\n",
      "[66]\tvalid_0's auc: 0.737507\n",
      "[67]\tvalid_0's auc: 0.73737\n",
      "[68]\tvalid_0's auc: 0.737218\n",
      "[69]\tvalid_0's auc: 0.737219\n",
      "[70]\tvalid_0's auc: 0.737772\n",
      "[71]\tvalid_0's auc: 0.73766\n",
      "[72]\tvalid_0's auc: 0.737723\n",
      "[73]\tvalid_0's auc: 0.737812\n",
      "[74]\tvalid_0's auc: 0.737558\n",
      "[75]\tvalid_0's auc: 0.738\n",
      "[76]\tvalid_0's auc: 0.738721\n",
      "[77]\tvalid_0's auc: 0.738553\n",
      "[78]\tvalid_0's auc: 0.738427\n",
      "[79]\tvalid_0's auc: 0.73851\n",
      "[80]\tvalid_0's auc: 0.738743\n",
      "[81]\tvalid_0's auc: 0.738966\n",
      "[82]\tvalid_0's auc: 0.738989\n",
      "[83]\tvalid_0's auc: 0.739683\n",
      "[84]\tvalid_0's auc: 0.739619\n",
      "[85]\tvalid_0's auc: 0.739699\n",
      "[86]\tvalid_0's auc: 0.739853\n",
      "[87]\tvalid_0's auc: 0.739794\n",
      "[88]\tvalid_0's auc: 0.73985\n",
      "[89]\tvalid_0's auc: 0.740273\n",
      "[90]\tvalid_0's auc: 0.74024\n",
      "[91]\tvalid_0's auc: 0.740697\n",
      "[92]\tvalid_0's auc: 0.740771\n",
      "[93]\tvalid_0's auc: 0.740647\n",
      "[94]\tvalid_0's auc: 0.740814\n",
      "[95]\tvalid_0's auc: 0.741261\n",
      "[96]\tvalid_0's auc: 0.740973\n",
      "[97]\tvalid_0's auc: 0.741321\n",
      "[98]\tvalid_0's auc: 0.741524\n",
      "[99]\tvalid_0's auc: 0.741306\n",
      "[100]\tvalid_0's auc: 0.741371\n",
      "[101]\tvalid_0's auc: 0.741619\n",
      "[102]\tvalid_0's auc: 0.741734\n",
      "[103]\tvalid_0's auc: 0.741866\n",
      "[104]\tvalid_0's auc: 0.741793\n",
      "[105]\tvalid_0's auc: 0.742048\n",
      "[106]\tvalid_0's auc: 0.741993\n",
      "[107]\tvalid_0's auc: 0.742137\n",
      "[108]\tvalid_0's auc: 0.742039\n",
      "[109]\tvalid_0's auc: 0.742255\n",
      "[110]\tvalid_0's auc: 0.742062\n",
      "[111]\tvalid_0's auc: 0.742307\n",
      "[112]\tvalid_0's auc: 0.742248\n",
      "[113]\tvalid_0's auc: 0.742419\n",
      "[114]\tvalid_0's auc: 0.742562\n",
      "[115]\tvalid_0's auc: 0.7425\n",
      "[116]\tvalid_0's auc: 0.742807\n",
      "[117]\tvalid_0's auc: 0.742833\n",
      "[118]\tvalid_0's auc: 0.742781\n",
      "[119]\tvalid_0's auc: 0.742921\n",
      "[120]\tvalid_0's auc: 0.742775\n",
      "[121]\tvalid_0's auc: 0.742889\n",
      "[122]\tvalid_0's auc: 0.742925\n",
      "[123]\tvalid_0's auc: 0.743006\n",
      "[124]\tvalid_0's auc: 0.74291\n",
      "[125]\tvalid_0's auc: 0.742965\n",
      "[126]\tvalid_0's auc: 0.74279\n",
      "[127]\tvalid_0's auc: 0.742906\n",
      "[128]\tvalid_0's auc: 0.742947\n",
      "[129]\tvalid_0's auc: 0.742866\n",
      "[130]\tvalid_0's auc: 0.742982\n",
      "[131]\tvalid_0's auc: 0.742945\n",
      "[132]\tvalid_0's auc: 0.742857\n",
      "[133]\tvalid_0's auc: 0.742879\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.743006\n"
     ]
    }
   ],
   "source": [
    "model_under_sample = lgbm_train(X_train2, X_valid, y_train2, y_valid, lgbm_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(seed):\n",
    "    sampler = RandomUnderSampler(random_state=seed, replacement=True)\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "    X_train2, X_valid, y_train2, y_valid = imbalanced_data_split(X_resampled, y_resampled, test_size=0.2)\n",
    "    model_bagging = lgbm_train(X_train2, X_valid, y_train2, y_valid, lgbm_params)\n",
    "    return model_bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.614669\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.633079\n",
      "[3]\tvalid_0's auc: 0.643412\n",
      "[4]\tvalid_0's auc: 0.667928\n",
      "[5]\tvalid_0's auc: 0.669054\n",
      "[6]\tvalid_0's auc: 0.676272\n",
      "[7]\tvalid_0's auc: 0.674874\n",
      "[8]\tvalid_0's auc: 0.673867\n",
      "[9]\tvalid_0's auc: 0.679047\n",
      "[10]\tvalid_0's auc: 0.679576\n",
      "[11]\tvalid_0's auc: 0.683217\n",
      "[12]\tvalid_0's auc: 0.682732\n",
      "[13]\tvalid_0's auc: 0.690798\n",
      "[14]\tvalid_0's auc: 0.690106\n",
      "[15]\tvalid_0's auc: 0.694641\n",
      "[16]\tvalid_0's auc: 0.695343\n",
      "[17]\tvalid_0's auc: 0.695279\n",
      "[18]\tvalid_0's auc: 0.696007\n",
      "[19]\tvalid_0's auc: 0.697422\n",
      "[20]\tvalid_0's auc: 0.700519\n",
      "[21]\tvalid_0's auc: 0.700822\n",
      "[22]\tvalid_0's auc: 0.700182\n",
      "[23]\tvalid_0's auc: 0.702093\n",
      "[24]\tvalid_0's auc: 0.703346\n",
      "[25]\tvalid_0's auc: 0.703014\n",
      "[26]\tvalid_0's auc: 0.706185\n",
      "[27]\tvalid_0's auc: 0.705718\n",
      "[28]\tvalid_0's auc: 0.708431\n",
      "[29]\tvalid_0's auc: 0.70949\n",
      "[30]\tvalid_0's auc: 0.709069\n",
      "[31]\tvalid_0's auc: 0.708456\n",
      "[32]\tvalid_0's auc: 0.709064\n",
      "[33]\tvalid_0's auc: 0.710338\n",
      "[34]\tvalid_0's auc: 0.710468\n",
      "[35]\tvalid_0's auc: 0.711548\n",
      "[36]\tvalid_0's auc: 0.711872\n",
      "[37]\tvalid_0's auc: 0.711862\n",
      "[38]\tvalid_0's auc: 0.712108\n",
      "[39]\tvalid_0's auc: 0.71276\n",
      "[40]\tvalid_0's auc: 0.713301\n",
      "[41]\tvalid_0's auc: 0.714827\n",
      "[42]\tvalid_0's auc: 0.714611\n",
      "[43]\tvalid_0's auc: 0.715093\n",
      "[44]\tvalid_0's auc: 0.715058\n",
      "[45]\tvalid_0's auc: 0.714973\n",
      "[46]\tvalid_0's auc: 0.715856\n",
      "[47]\tvalid_0's auc: 0.715959\n",
      "[48]\tvalid_0's auc: 0.71555\n",
      "[49]\tvalid_0's auc: 0.716431\n",
      "[50]\tvalid_0's auc: 0.716619\n",
      "[51]\tvalid_0's auc: 0.716472\n",
      "[52]\tvalid_0's auc: 0.716652\n",
      "[53]\tvalid_0's auc: 0.716765\n",
      "[54]\tvalid_0's auc: 0.716811\n",
      "[55]\tvalid_0's auc: 0.716915\n",
      "[56]\tvalid_0's auc: 0.716453\n",
      "[57]\tvalid_0's auc: 0.716994\n",
      "[58]\tvalid_0's auc: 0.717061\n",
      "[59]\tvalid_0's auc: 0.716737\n",
      "[60]\tvalid_0's auc: 0.716947\n",
      "[61]\tvalid_0's auc: 0.716859\n",
      "[62]\tvalid_0's auc: 0.717302\n",
      "[63]\tvalid_0's auc: 0.717949\n",
      "[64]\tvalid_0's auc: 0.717957\n",
      "[65]\tvalid_0's auc: 0.718532\n",
      "[66]\tvalid_0's auc: 0.719003\n",
      "[67]\tvalid_0's auc: 0.719021\n",
      "[68]\tvalid_0's auc: 0.719319\n",
      "[69]\tvalid_0's auc: 0.718921\n",
      "[70]\tvalid_0's auc: 0.719538\n",
      "[71]\tvalid_0's auc: 0.719783\n",
      "[72]\tvalid_0's auc: 0.71993\n",
      "[73]\tvalid_0's auc: 0.719882\n",
      "[74]\tvalid_0's auc: 0.719933\n",
      "[75]\tvalid_0's auc: 0.719585\n",
      "[76]\tvalid_0's auc: 0.719481\n",
      "[77]\tvalid_0's auc: 0.719652\n",
      "[78]\tvalid_0's auc: 0.719848\n",
      "[79]\tvalid_0's auc: 0.71987\n",
      "[80]\tvalid_0's auc: 0.719808\n",
      "[81]\tvalid_0's auc: 0.719998\n",
      "[82]\tvalid_0's auc: 0.720149\n",
      "[83]\tvalid_0's auc: 0.72102\n",
      "[84]\tvalid_0's auc: 0.721161\n",
      "[85]\tvalid_0's auc: 0.721126\n",
      "[86]\tvalid_0's auc: 0.72094\n",
      "[87]\tvalid_0's auc: 0.720845\n",
      "[88]\tvalid_0's auc: 0.721039\n",
      "[89]\tvalid_0's auc: 0.720976\n",
      "[90]\tvalid_0's auc: 0.721737\n",
      "[91]\tvalid_0's auc: 0.722157\n",
      "[92]\tvalid_0's auc: 0.722195\n",
      "[93]\tvalid_0's auc: 0.722339\n",
      "[94]\tvalid_0's auc: 0.722938\n",
      "[95]\tvalid_0's auc: 0.722772\n",
      "[96]\tvalid_0's auc: 0.722735\n",
      "[97]\tvalid_0's auc: 0.722763\n",
      "[98]\tvalid_0's auc: 0.72285\n",
      "[99]\tvalid_0's auc: 0.722914\n",
      "[100]\tvalid_0's auc: 0.72333\n",
      "[101]\tvalid_0's auc: 0.723313\n",
      "[102]\tvalid_0's auc: 0.723414\n",
      "[103]\tvalid_0's auc: 0.723892\n",
      "[104]\tvalid_0's auc: 0.723876\n",
      "[105]\tvalid_0's auc: 0.724076\n",
      "[106]\tvalid_0's auc: 0.724183\n",
      "[107]\tvalid_0's auc: 0.724129\n",
      "[108]\tvalid_0's auc: 0.724052\n",
      "[109]\tvalid_0's auc: 0.723837\n",
      "[110]\tvalid_0's auc: 0.723868\n",
      "[111]\tvalid_0's auc: 0.72443\n",
      "[112]\tvalid_0's auc: 0.724769\n",
      "[113]\tvalid_0's auc: 0.724832\n",
      "[114]\tvalid_0's auc: 0.724722\n",
      "[115]\tvalid_0's auc: 0.724741\n",
      "[116]\tvalid_0's auc: 0.724817\n",
      "[117]\tvalid_0's auc: 0.724497\n",
      "[118]\tvalid_0's auc: 0.724683\n",
      "[119]\tvalid_0's auc: 0.724605\n",
      "[120]\tvalid_0's auc: 0.724676\n",
      "[121]\tvalid_0's auc: 0.725006\n",
      "[122]\tvalid_0's auc: 0.725098\n",
      "[123]\tvalid_0's auc: 0.725331\n",
      "[124]\tvalid_0's auc: 0.725275\n",
      "[125]\tvalid_0's auc: 0.725182\n",
      "[126]\tvalid_0's auc: 0.725124\n",
      "[127]\tvalid_0's auc: 0.725118\n",
      "[128]\tvalid_0's auc: 0.725182\n",
      "[129]\tvalid_0's auc: 0.725191\n",
      "[130]\tvalid_0's auc: 0.725625\n",
      "[131]\tvalid_0's auc: 0.72548\n",
      "[132]\tvalid_0's auc: 0.725517\n",
      "[133]\tvalid_0's auc: 0.725397\n",
      "[134]\tvalid_0's auc: 0.725428\n",
      "[135]\tvalid_0's auc: 0.72555\n",
      "[136]\tvalid_0's auc: 0.725633\n",
      "[137]\tvalid_0's auc: 0.725609\n",
      "[138]\tvalid_0's auc: 0.725579\n",
      "[139]\tvalid_0's auc: 0.725592\n",
      "[140]\tvalid_0's auc: 0.725456\n",
      "[141]\tvalid_0's auc: 0.725264\n",
      "[142]\tvalid_0's auc: 0.725214\n",
      "[143]\tvalid_0's auc: 0.725451\n",
      "[144]\tvalid_0's auc: 0.725486\n",
      "[145]\tvalid_0's auc: 0.725655\n",
      "[146]\tvalid_0's auc: 0.725589\n",
      "[147]\tvalid_0's auc: 0.725596\n",
      "[148]\tvalid_0's auc: 0.725638\n",
      "[149]\tvalid_0's auc: 0.725492\n",
      "[150]\tvalid_0's auc: 0.725392\n",
      "[151]\tvalid_0's auc: 0.72532\n",
      "[152]\tvalid_0's auc: 0.725365\n",
      "[153]\tvalid_0's auc: 0.725284\n",
      "[154]\tvalid_0's auc: 0.725299\n",
      "[155]\tvalid_0's auc: 0.725621\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.725655\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.628375\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.649087\n",
      "[3]\tvalid_0's auc: 0.653841\n",
      "[4]\tvalid_0's auc: 0.681812\n",
      "[5]\tvalid_0's auc: 0.67951\n",
      "[6]\tvalid_0's auc: 0.685916\n",
      "[7]\tvalid_0's auc: 0.687803\n",
      "[8]\tvalid_0's auc: 0.68931\n",
      "[9]\tvalid_0's auc: 0.694378\n",
      "[10]\tvalid_0's auc: 0.693764\n",
      "[11]\tvalid_0's auc: 0.700689\n",
      "[12]\tvalid_0's auc: 0.705543\n",
      "[13]\tvalid_0's auc: 0.707846\n",
      "[14]\tvalid_0's auc: 0.708522\n",
      "[15]\tvalid_0's auc: 0.707763\n",
      "[16]\tvalid_0's auc: 0.708182\n",
      "[17]\tvalid_0's auc: 0.714042\n",
      "[18]\tvalid_0's auc: 0.716501\n",
      "[19]\tvalid_0's auc: 0.717409\n",
      "[20]\tvalid_0's auc: 0.718934\n",
      "[21]\tvalid_0's auc: 0.721949\n",
      "[22]\tvalid_0's auc: 0.722581\n",
      "[23]\tvalid_0's auc: 0.722905\n",
      "[24]\tvalid_0's auc: 0.725299\n",
      "[25]\tvalid_0's auc: 0.724608\n",
      "[26]\tvalid_0's auc: 0.7262\n",
      "[27]\tvalid_0's auc: 0.726237\n",
      "[28]\tvalid_0's auc: 0.728251\n",
      "[29]\tvalid_0's auc: 0.728234\n",
      "[30]\tvalid_0's auc: 0.729477\n",
      "[31]\tvalid_0's auc: 0.729398\n",
      "[32]\tvalid_0's auc: 0.729175\n",
      "[33]\tvalid_0's auc: 0.729712\n",
      "[34]\tvalid_0's auc: 0.730968\n",
      "[35]\tvalid_0's auc: 0.731425\n",
      "[36]\tvalid_0's auc: 0.73278\n",
      "[37]\tvalid_0's auc: 0.732289\n",
      "[38]\tvalid_0's auc: 0.732694\n",
      "[39]\tvalid_0's auc: 0.733105\n",
      "[40]\tvalid_0's auc: 0.733781\n",
      "[41]\tvalid_0's auc: 0.733632\n",
      "[42]\tvalid_0's auc: 0.733716\n",
      "[43]\tvalid_0's auc: 0.734381\n",
      "[44]\tvalid_0's auc: 0.733965\n",
      "[45]\tvalid_0's auc: 0.73412\n",
      "[46]\tvalid_0's auc: 0.73479\n",
      "[47]\tvalid_0's auc: 0.73549\n",
      "[48]\tvalid_0's auc: 0.735903\n",
      "[49]\tvalid_0's auc: 0.735929\n",
      "[50]\tvalid_0's auc: 0.735674\n",
      "[51]\tvalid_0's auc: 0.735428\n",
      "[52]\tvalid_0's auc: 0.736011\n",
      "[53]\tvalid_0's auc: 0.736446\n",
      "[54]\tvalid_0's auc: 0.737002\n",
      "[55]\tvalid_0's auc: 0.736523\n",
      "[56]\tvalid_0's auc: 0.737257\n",
      "[57]\tvalid_0's auc: 0.737364\n",
      "[58]\tvalid_0's auc: 0.737526\n",
      "[59]\tvalid_0's auc: 0.737817\n",
      "[60]\tvalid_0's auc: 0.737595\n",
      "[61]\tvalid_0's auc: 0.738262\n",
      "[62]\tvalid_0's auc: 0.737952\n",
      "[63]\tvalid_0's auc: 0.738042\n",
      "[64]\tvalid_0's auc: 0.738107\n",
      "[65]\tvalid_0's auc: 0.738332\n",
      "[66]\tvalid_0's auc: 0.738719\n",
      "[67]\tvalid_0's auc: 0.738717\n",
      "[68]\tvalid_0's auc: 0.739307\n",
      "[69]\tvalid_0's auc: 0.739573\n",
      "[70]\tvalid_0's auc: 0.739597\n",
      "[71]\tvalid_0's auc: 0.739508\n",
      "[72]\tvalid_0's auc: 0.739693\n",
      "[73]\tvalid_0's auc: 0.739813\n",
      "[74]\tvalid_0's auc: 0.739936\n",
      "[75]\tvalid_0's auc: 0.739853\n",
      "[76]\tvalid_0's auc: 0.73979\n",
      "[77]\tvalid_0's auc: 0.740103\n",
      "[78]\tvalid_0's auc: 0.740653\n",
      "[79]\tvalid_0's auc: 0.740532\n",
      "[80]\tvalid_0's auc: 0.740483\n",
      "[81]\tvalid_0's auc: 0.740652\n",
      "[82]\tvalid_0's auc: 0.740767\n",
      "[83]\tvalid_0's auc: 0.740581\n",
      "[84]\tvalid_0's auc: 0.740718\n",
      "[85]\tvalid_0's auc: 0.740903\n",
      "[86]\tvalid_0's auc: 0.741124\n",
      "[87]\tvalid_0's auc: 0.741016\n",
      "[88]\tvalid_0's auc: 0.741464\n",
      "[89]\tvalid_0's auc: 0.741602\n",
      "[90]\tvalid_0's auc: 0.741809\n",
      "[91]\tvalid_0's auc: 0.741625\n",
      "[92]\tvalid_0's auc: 0.741436\n",
      "[93]\tvalid_0's auc: 0.741538\n",
      "[94]\tvalid_0's auc: 0.741568\n",
      "[95]\tvalid_0's auc: 0.741568\n",
      "[96]\tvalid_0's auc: 0.741699\n",
      "[97]\tvalid_0's auc: 0.741772\n",
      "[98]\tvalid_0's auc: 0.741446\n",
      "[99]\tvalid_0's auc: 0.741792\n",
      "[100]\tvalid_0's auc: 0.741855\n",
      "[101]\tvalid_0's auc: 0.742018\n",
      "[102]\tvalid_0's auc: 0.742186\n",
      "[103]\tvalid_0's auc: 0.742375\n",
      "[104]\tvalid_0's auc: 0.742383\n",
      "[105]\tvalid_0's auc: 0.742381\n",
      "[106]\tvalid_0's auc: 0.742286\n",
      "[107]\tvalid_0's auc: 0.74264\n",
      "[108]\tvalid_0's auc: 0.742539\n",
      "[109]\tvalid_0's auc: 0.742656\n",
      "[110]\tvalid_0's auc: 0.742829\n",
      "[111]\tvalid_0's auc: 0.742742\n",
      "[112]\tvalid_0's auc: 0.742748\n",
      "[113]\tvalid_0's auc: 0.742896\n",
      "[114]\tvalid_0's auc: 0.742836\n",
      "[115]\tvalid_0's auc: 0.742819\n",
      "[116]\tvalid_0's auc: 0.74288\n",
      "[117]\tvalid_0's auc: 0.742784\n",
      "[118]\tvalid_0's auc: 0.742821\n",
      "[119]\tvalid_0's auc: 0.742824\n",
      "[120]\tvalid_0's auc: 0.74266\n",
      "[121]\tvalid_0's auc: 0.742585\n",
      "[122]\tvalid_0's auc: 0.742582\n",
      "[123]\tvalid_0's auc: 0.742586\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.742896\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.621912\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.623406\n",
      "[3]\tvalid_0's auc: 0.643477\n",
      "[4]\tvalid_0's auc: 0.653646\n",
      "[5]\tvalid_0's auc: 0.660824\n",
      "[6]\tvalid_0's auc: 0.669422\n",
      "[7]\tvalid_0's auc: 0.691408\n",
      "[8]\tvalid_0's auc: 0.692203\n",
      "[9]\tvalid_0's auc: 0.697717\n",
      "[10]\tvalid_0's auc: 0.69852\n",
      "[11]\tvalid_0's auc: 0.700703\n",
      "[12]\tvalid_0's auc: 0.708755\n",
      "[13]\tvalid_0's auc: 0.710863\n",
      "[14]\tvalid_0's auc: 0.713343\n",
      "[15]\tvalid_0's auc: 0.714206\n",
      "[16]\tvalid_0's auc: 0.71322\n",
      "[17]\tvalid_0's auc: 0.714377\n",
      "[18]\tvalid_0's auc: 0.717481\n",
      "[19]\tvalid_0's auc: 0.716527\n",
      "[20]\tvalid_0's auc: 0.716968\n",
      "[21]\tvalid_0's auc: 0.720262\n",
      "[22]\tvalid_0's auc: 0.72071\n",
      "[23]\tvalid_0's auc: 0.722838\n",
      "[24]\tvalid_0's auc: 0.723357\n",
      "[25]\tvalid_0's auc: 0.723353\n",
      "[26]\tvalid_0's auc: 0.723113\n",
      "[27]\tvalid_0's auc: 0.724792\n",
      "[28]\tvalid_0's auc: 0.724902\n",
      "[29]\tvalid_0's auc: 0.72474\n",
      "[30]\tvalid_0's auc: 0.72592\n",
      "[31]\tvalid_0's auc: 0.727658\n",
      "[32]\tvalid_0's auc: 0.727142\n",
      "[33]\tvalid_0's auc: 0.728744\n",
      "[34]\tvalid_0's auc: 0.728444\n",
      "[35]\tvalid_0's auc: 0.728518\n",
      "[36]\tvalid_0's auc: 0.729528\n",
      "[37]\tvalid_0's auc: 0.729002\n",
      "[38]\tvalid_0's auc: 0.72892\n",
      "[39]\tvalid_0's auc: 0.729609\n",
      "[40]\tvalid_0's auc: 0.730089\n",
      "[41]\tvalid_0's auc: 0.731934\n",
      "[42]\tvalid_0's auc: 0.731389\n",
      "[43]\tvalid_0's auc: 0.731955\n",
      "[44]\tvalid_0's auc: 0.732061\n",
      "[45]\tvalid_0's auc: 0.731999\n",
      "[46]\tvalid_0's auc: 0.731985\n",
      "[47]\tvalid_0's auc: 0.732581\n",
      "[48]\tvalid_0's auc: 0.732272\n",
      "[49]\tvalid_0's auc: 0.732406\n",
      "[50]\tvalid_0's auc: 0.733256\n",
      "[51]\tvalid_0's auc: 0.733575\n",
      "[52]\tvalid_0's auc: 0.733703\n",
      "[53]\tvalid_0's auc: 0.733897\n",
      "[54]\tvalid_0's auc: 0.733903\n",
      "[55]\tvalid_0's auc: 0.733716\n",
      "[56]\tvalid_0's auc: 0.734417\n",
      "[57]\tvalid_0's auc: 0.734677\n",
      "[58]\tvalid_0's auc: 0.734214\n",
      "[59]\tvalid_0's auc: 0.734086\n",
      "[60]\tvalid_0's auc: 0.734328\n",
      "[61]\tvalid_0's auc: 0.734567\n",
      "[62]\tvalid_0's auc: 0.734389\n",
      "[63]\tvalid_0's auc: 0.734212\n",
      "[64]\tvalid_0's auc: 0.734341\n",
      "[65]\tvalid_0's auc: 0.734064\n",
      "[66]\tvalid_0's auc: 0.73376\n",
      "[67]\tvalid_0's auc: 0.733901\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.734677\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.612812\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.6649\n",
      "[3]\tvalid_0's auc: 0.669999\n",
      "[4]\tvalid_0's auc: 0.676177\n",
      "[5]\tvalid_0's auc: 0.690782\n",
      "[6]\tvalid_0's auc: 0.692124\n",
      "[7]\tvalid_0's auc: 0.696319\n",
      "[8]\tvalid_0's auc: 0.699438\n",
      "[9]\tvalid_0's auc: 0.703107\n",
      "[10]\tvalid_0's auc: 0.704644\n",
      "[11]\tvalid_0's auc: 0.704827\n",
      "[12]\tvalid_0's auc: 0.706095\n",
      "[13]\tvalid_0's auc: 0.706165\n",
      "[14]\tvalid_0's auc: 0.707238\n",
      "[15]\tvalid_0's auc: 0.70994\n",
      "[16]\tvalid_0's auc: 0.713608\n",
      "[17]\tvalid_0's auc: 0.715523\n",
      "[18]\tvalid_0's auc: 0.717471\n",
      "[19]\tvalid_0's auc: 0.718151\n",
      "[20]\tvalid_0's auc: 0.718489\n",
      "[21]\tvalid_0's auc: 0.719804\n",
      "[22]\tvalid_0's auc: 0.7201\n",
      "[23]\tvalid_0's auc: 0.720543\n",
      "[24]\tvalid_0's auc: 0.724225\n",
      "[25]\tvalid_0's auc: 0.724066\n",
      "[26]\tvalid_0's auc: 0.723886\n",
      "[27]\tvalid_0's auc: 0.724717\n",
      "[28]\tvalid_0's auc: 0.725699\n",
      "[29]\tvalid_0's auc: 0.725688\n",
      "[30]\tvalid_0's auc: 0.726571\n",
      "[31]\tvalid_0's auc: 0.728804\n",
      "[32]\tvalid_0's auc: 0.728311\n",
      "[33]\tvalid_0's auc: 0.729666\n",
      "[34]\tvalid_0's auc: 0.729919\n",
      "[35]\tvalid_0's auc: 0.729874\n",
      "[36]\tvalid_0's auc: 0.730532\n",
      "[37]\tvalid_0's auc: 0.731371\n",
      "[38]\tvalid_0's auc: 0.731219\n",
      "[39]\tvalid_0's auc: 0.731503\n",
      "[40]\tvalid_0's auc: 0.731834\n",
      "[41]\tvalid_0's auc: 0.731902\n",
      "[42]\tvalid_0's auc: 0.732183\n",
      "[43]\tvalid_0's auc: 0.733088\n",
      "[44]\tvalid_0's auc: 0.733124\n",
      "[45]\tvalid_0's auc: 0.733199\n",
      "[46]\tvalid_0's auc: 0.733245\n",
      "[47]\tvalid_0's auc: 0.73313\n",
      "[48]\tvalid_0's auc: 0.733639\n",
      "[49]\tvalid_0's auc: 0.733686\n",
      "[50]\tvalid_0's auc: 0.733547\n",
      "[51]\tvalid_0's auc: 0.733465\n",
      "[52]\tvalid_0's auc: 0.734027\n",
      "[53]\tvalid_0's auc: 0.733912\n",
      "[54]\tvalid_0's auc: 0.734246\n",
      "[55]\tvalid_0's auc: 0.734358\n",
      "[56]\tvalid_0's auc: 0.734615\n",
      "[57]\tvalid_0's auc: 0.734771\n",
      "[58]\tvalid_0's auc: 0.735152\n",
      "[59]\tvalid_0's auc: 0.735325\n",
      "[60]\tvalid_0's auc: 0.73541\n",
      "[61]\tvalid_0's auc: 0.735581\n",
      "[62]\tvalid_0's auc: 0.735455\n",
      "[63]\tvalid_0's auc: 0.735739\n",
      "[64]\tvalid_0's auc: 0.735405\n",
      "[65]\tvalid_0's auc: 0.735987\n",
      "[66]\tvalid_0's auc: 0.736076\n",
      "[67]\tvalid_0's auc: 0.736162\n",
      "[68]\tvalid_0's auc: 0.736471\n",
      "[69]\tvalid_0's auc: 0.736701\n",
      "[70]\tvalid_0's auc: 0.736788\n",
      "[71]\tvalid_0's auc: 0.737169\n",
      "[72]\tvalid_0's auc: 0.737329\n",
      "[73]\tvalid_0's auc: 0.737371\n",
      "[74]\tvalid_0's auc: 0.737621\n",
      "[75]\tvalid_0's auc: 0.738058\n",
      "[76]\tvalid_0's auc: 0.73784\n",
      "[77]\tvalid_0's auc: 0.73762\n",
      "[78]\tvalid_0's auc: 0.737576\n",
      "[79]\tvalid_0's auc: 0.737643\n",
      "[80]\tvalid_0's auc: 0.737733\n",
      "[81]\tvalid_0's auc: 0.738346\n",
      "[82]\tvalid_0's auc: 0.738604\n",
      "[83]\tvalid_0's auc: 0.738311\n",
      "[84]\tvalid_0's auc: 0.738526\n",
      "[85]\tvalid_0's auc: 0.738462\n",
      "[86]\tvalid_0's auc: 0.738498\n",
      "[87]\tvalid_0's auc: 0.738722\n",
      "[88]\tvalid_0's auc: 0.738772\n",
      "[89]\tvalid_0's auc: 0.738769\n",
      "[90]\tvalid_0's auc: 0.7395\n",
      "[91]\tvalid_0's auc: 0.739582\n",
      "[92]\tvalid_0's auc: 0.739347\n",
      "[93]\tvalid_0's auc: 0.73927\n",
      "[94]\tvalid_0's auc: 0.739287\n",
      "[95]\tvalid_0's auc: 0.739442\n",
      "[96]\tvalid_0's auc: 0.739235\n",
      "[97]\tvalid_0's auc: 0.739292\n",
      "[98]\tvalid_0's auc: 0.739162\n",
      "[99]\tvalid_0's auc: 0.739438\n",
      "[100]\tvalid_0's auc: 0.739464\n",
      "[101]\tvalid_0's auc: 0.739601\n",
      "[102]\tvalid_0's auc: 0.739579\n",
      "[103]\tvalid_0's auc: 0.739792\n",
      "[104]\tvalid_0's auc: 0.740055\n",
      "[105]\tvalid_0's auc: 0.740095\n",
      "[106]\tvalid_0's auc: 0.739773\n",
      "[107]\tvalid_0's auc: 0.739862\n",
      "[108]\tvalid_0's auc: 0.740004\n",
      "[109]\tvalid_0's auc: 0.739977\n",
      "[110]\tvalid_0's auc: 0.739921\n",
      "[111]\tvalid_0's auc: 0.739949\n",
      "[112]\tvalid_0's auc: 0.739962\n",
      "[113]\tvalid_0's auc: 0.740052\n",
      "[114]\tvalid_0's auc: 0.740175\n",
      "[115]\tvalid_0's auc: 0.740239\n",
      "[116]\tvalid_0's auc: 0.740046\n",
      "[117]\tvalid_0's auc: 0.739963\n",
      "[118]\tvalid_0's auc: 0.740125\n",
      "[119]\tvalid_0's auc: 0.740334\n",
      "[120]\tvalid_0's auc: 0.740467\n",
      "[121]\tvalid_0's auc: 0.740487\n",
      "[122]\tvalid_0's auc: 0.740516\n",
      "[123]\tvalid_0's auc: 0.740397\n",
      "[124]\tvalid_0's auc: 0.740585\n",
      "[125]\tvalid_0's auc: 0.74072\n",
      "[126]\tvalid_0's auc: 0.740743\n",
      "[127]\tvalid_0's auc: 0.741079\n",
      "[128]\tvalid_0's auc: 0.741168\n",
      "[129]\tvalid_0's auc: 0.741074\n",
      "[130]\tvalid_0's auc: 0.741118\n",
      "[131]\tvalid_0's auc: 0.741382\n",
      "[132]\tvalid_0's auc: 0.741345\n",
      "[133]\tvalid_0's auc: 0.741421\n",
      "[134]\tvalid_0's auc: 0.741496\n",
      "[135]\tvalid_0's auc: 0.741457\n",
      "[136]\tvalid_0's auc: 0.741418\n",
      "[137]\tvalid_0's auc: 0.741474\n",
      "[138]\tvalid_0's auc: 0.74142\n",
      "[139]\tvalid_0's auc: 0.741451\n",
      "[140]\tvalid_0's auc: 0.741478\n",
      "[141]\tvalid_0's auc: 0.741298\n",
      "[142]\tvalid_0's auc: 0.741043\n",
      "[143]\tvalid_0's auc: 0.740969\n",
      "[144]\tvalid_0's auc: 0.740839\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.741496\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.620044\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.634267\n",
      "[3]\tvalid_0's auc: 0.645678\n",
      "[4]\tvalid_0's auc: 0.653279\n",
      "[5]\tvalid_0's auc: 0.671957\n",
      "[6]\tvalid_0's auc: 0.687935\n",
      "[7]\tvalid_0's auc: 0.688622\n",
      "[8]\tvalid_0's auc: 0.697163\n",
      "[9]\tvalid_0's auc: 0.698675\n",
      "[10]\tvalid_0's auc: 0.696021\n",
      "[11]\tvalid_0's auc: 0.698634\n",
      "[12]\tvalid_0's auc: 0.701073\n",
      "[13]\tvalid_0's auc: 0.699782\n",
      "[14]\tvalid_0's auc: 0.706092\n",
      "[15]\tvalid_0's auc: 0.709155\n",
      "[16]\tvalid_0's auc: 0.711166\n",
      "[17]\tvalid_0's auc: 0.712918\n",
      "[18]\tvalid_0's auc: 0.711794\n",
      "[19]\tvalid_0's auc: 0.712683\n",
      "[20]\tvalid_0's auc: 0.711487\n",
      "[21]\tvalid_0's auc: 0.71145\n",
      "[22]\tvalid_0's auc: 0.712657\n",
      "[23]\tvalid_0's auc: 0.716814\n",
      "[24]\tvalid_0's auc: 0.71634\n",
      "[25]\tvalid_0's auc: 0.71698\n",
      "[26]\tvalid_0's auc: 0.717918\n",
      "[27]\tvalid_0's auc: 0.720251\n",
      "[28]\tvalid_0's auc: 0.719819\n",
      "[29]\tvalid_0's auc: 0.720731\n",
      "[30]\tvalid_0's auc: 0.72069\n",
      "[31]\tvalid_0's auc: 0.72088\n",
      "[32]\tvalid_0's auc: 0.721219\n",
      "[33]\tvalid_0's auc: 0.722733\n",
      "[34]\tvalid_0's auc: 0.723795\n",
      "[35]\tvalid_0's auc: 0.725653\n",
      "[36]\tvalid_0's auc: 0.725951\n",
      "[37]\tvalid_0's auc: 0.725853\n",
      "[38]\tvalid_0's auc: 0.725591\n",
      "[39]\tvalid_0's auc: 0.726259\n",
      "[40]\tvalid_0's auc: 0.727497\n",
      "[41]\tvalid_0's auc: 0.727568\n",
      "[42]\tvalid_0's auc: 0.726817\n",
      "[43]\tvalid_0's auc: 0.727127\n",
      "[44]\tvalid_0's auc: 0.727409\n",
      "[45]\tvalid_0's auc: 0.72713\n",
      "[46]\tvalid_0's auc: 0.726471\n",
      "[47]\tvalid_0's auc: 0.726884\n",
      "[48]\tvalid_0's auc: 0.727919\n",
      "[49]\tvalid_0's auc: 0.72849\n",
      "[50]\tvalid_0's auc: 0.728254\n",
      "[51]\tvalid_0's auc: 0.728543\n",
      "[52]\tvalid_0's auc: 0.728492\n",
      "[53]\tvalid_0's auc: 0.72888\n",
      "[54]\tvalid_0's auc: 0.729165\n",
      "[55]\tvalid_0's auc: 0.729418\n",
      "[56]\tvalid_0's auc: 0.729461\n",
      "[57]\tvalid_0's auc: 0.728897\n",
      "[58]\tvalid_0's auc: 0.728689\n",
      "[59]\tvalid_0's auc: 0.728789\n",
      "[60]\tvalid_0's auc: 0.729216\n",
      "[61]\tvalid_0's auc: 0.729224\n",
      "[62]\tvalid_0's auc: 0.729028\n",
      "[63]\tvalid_0's auc: 0.730139\n",
      "[64]\tvalid_0's auc: 0.730379\n",
      "[65]\tvalid_0's auc: 0.730764\n",
      "[66]\tvalid_0's auc: 0.730974\n",
      "[67]\tvalid_0's auc: 0.730625\n",
      "[68]\tvalid_0's auc: 0.730669\n",
      "[69]\tvalid_0's auc: 0.731546\n",
      "[70]\tvalid_0's auc: 0.731974\n",
      "[71]\tvalid_0's auc: 0.732439\n",
      "[72]\tvalid_0's auc: 0.732319\n",
      "[73]\tvalid_0's auc: 0.732486\n",
      "[74]\tvalid_0's auc: 0.732441\n",
      "[75]\tvalid_0's auc: 0.732886\n",
      "[76]\tvalid_0's auc: 0.733145\n",
      "[77]\tvalid_0's auc: 0.73326\n",
      "[78]\tvalid_0's auc: 0.733578\n",
      "[79]\tvalid_0's auc: 0.733412\n",
      "[80]\tvalid_0's auc: 0.733515\n",
      "[81]\tvalid_0's auc: 0.73316\n",
      "[82]\tvalid_0's auc: 0.733374\n",
      "[83]\tvalid_0's auc: 0.73337\n",
      "[84]\tvalid_0's auc: 0.733909\n",
      "[85]\tvalid_0's auc: 0.733968\n",
      "[86]\tvalid_0's auc: 0.734575\n",
      "[87]\tvalid_0's auc: 0.734695\n",
      "[88]\tvalid_0's auc: 0.735\n",
      "[89]\tvalid_0's auc: 0.734854\n",
      "[90]\tvalid_0's auc: 0.734912\n",
      "[91]\tvalid_0's auc: 0.735159\n",
      "[92]\tvalid_0's auc: 0.735581\n",
      "[93]\tvalid_0's auc: 0.736098\n",
      "[94]\tvalid_0's auc: 0.735994\n",
      "[95]\tvalid_0's auc: 0.736042\n",
      "[96]\tvalid_0's auc: 0.736076\n",
      "[97]\tvalid_0's auc: 0.736212\n",
      "[98]\tvalid_0's auc: 0.736276\n",
      "[99]\tvalid_0's auc: 0.736114\n",
      "[100]\tvalid_0's auc: 0.736032\n",
      "[101]\tvalid_0's auc: 0.73646\n",
      "[102]\tvalid_0's auc: 0.736538\n",
      "[103]\tvalid_0's auc: 0.736647\n",
      "[104]\tvalid_0's auc: 0.736671\n",
      "[105]\tvalid_0's auc: 0.736882\n",
      "[106]\tvalid_0's auc: 0.736935\n",
      "[107]\tvalid_0's auc: 0.737167\n",
      "[108]\tvalid_0's auc: 0.737364\n",
      "[109]\tvalid_0's auc: 0.737704\n",
      "[110]\tvalid_0's auc: 0.737771\n",
      "[111]\tvalid_0's auc: 0.737263\n",
      "[112]\tvalid_0's auc: 0.737249\n",
      "[113]\tvalid_0's auc: 0.737292\n",
      "[114]\tvalid_0's auc: 0.737168\n",
      "[115]\tvalid_0's auc: 0.73725\n",
      "[116]\tvalid_0's auc: 0.73759\n",
      "[117]\tvalid_0's auc: 0.737466\n",
      "[118]\tvalid_0's auc: 0.737606\n",
      "[119]\tvalid_0's auc: 0.737511\n",
      "[120]\tvalid_0's auc: 0.737664\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.737771\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.620915\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.624591\n",
      "[3]\tvalid_0's auc: 0.657735\n",
      "[4]\tvalid_0's auc: 0.658483\n",
      "[5]\tvalid_0's auc: 0.669088\n",
      "[6]\tvalid_0's auc: 0.680018\n",
      "[7]\tvalid_0's auc: 0.683961\n",
      "[8]\tvalid_0's auc: 0.699067\n",
      "[9]\tvalid_0's auc: 0.702332\n",
      "[10]\tvalid_0's auc: 0.701979\n",
      "[11]\tvalid_0's auc: 0.704156\n",
      "[12]\tvalid_0's auc: 0.704761\n",
      "[13]\tvalid_0's auc: 0.712007\n",
      "[14]\tvalid_0's auc: 0.712089\n",
      "[15]\tvalid_0's auc: 0.715322\n",
      "[16]\tvalid_0's auc: 0.715295\n",
      "[17]\tvalid_0's auc: 0.716055\n",
      "[18]\tvalid_0's auc: 0.715815\n",
      "[19]\tvalid_0's auc: 0.718176\n",
      "[20]\tvalid_0's auc: 0.719295\n",
      "[21]\tvalid_0's auc: 0.719461\n",
      "[22]\tvalid_0's auc: 0.720744\n",
      "[23]\tvalid_0's auc: 0.72031\n",
      "[24]\tvalid_0's auc: 0.721504\n",
      "[25]\tvalid_0's auc: 0.721886\n",
      "[26]\tvalid_0's auc: 0.724567\n",
      "[27]\tvalid_0's auc: 0.726227\n",
      "[28]\tvalid_0's auc: 0.726265\n",
      "[29]\tvalid_0's auc: 0.726189\n",
      "[30]\tvalid_0's auc: 0.726714\n",
      "[31]\tvalid_0's auc: 0.726916\n",
      "[32]\tvalid_0's auc: 0.726092\n",
      "[33]\tvalid_0's auc: 0.727601\n",
      "[34]\tvalid_0's auc: 0.728252\n",
      "[35]\tvalid_0's auc: 0.72823\n",
      "[36]\tvalid_0's auc: 0.728545\n",
      "[37]\tvalid_0's auc: 0.728645\n",
      "[38]\tvalid_0's auc: 0.729274\n",
      "[39]\tvalid_0's auc: 0.728866\n",
      "[40]\tvalid_0's auc: 0.729172\n",
      "[41]\tvalid_0's auc: 0.730266\n",
      "[42]\tvalid_0's auc: 0.73031\n",
      "[43]\tvalid_0's auc: 0.730503\n",
      "[44]\tvalid_0's auc: 0.73086\n",
      "[45]\tvalid_0's auc: 0.730672\n",
      "[46]\tvalid_0's auc: 0.730615\n",
      "[47]\tvalid_0's auc: 0.731409\n",
      "[48]\tvalid_0's auc: 0.732253\n",
      "[49]\tvalid_0's auc: 0.732173\n",
      "[50]\tvalid_0's auc: 0.732032\n",
      "[51]\tvalid_0's auc: 0.732649\n",
      "[52]\tvalid_0's auc: 0.732987\n",
      "[53]\tvalid_0's auc: 0.732956\n",
      "[54]\tvalid_0's auc: 0.733572\n",
      "[55]\tvalid_0's auc: 0.734602\n",
      "[56]\tvalid_0's auc: 0.734616\n",
      "[57]\tvalid_0's auc: 0.734561\n",
      "[58]\tvalid_0's auc: 0.735132\n",
      "[59]\tvalid_0's auc: 0.7351\n",
      "[60]\tvalid_0's auc: 0.735384\n",
      "[61]\tvalid_0's auc: 0.735523\n",
      "[62]\tvalid_0's auc: 0.735685\n",
      "[63]\tvalid_0's auc: 0.735607\n",
      "[64]\tvalid_0's auc: 0.735404\n",
      "[65]\tvalid_0's auc: 0.735657\n",
      "[66]\tvalid_0's auc: 0.735807\n",
      "[67]\tvalid_0's auc: 0.736158\n",
      "[68]\tvalid_0's auc: 0.735954\n",
      "[69]\tvalid_0's auc: 0.736098\n",
      "[70]\tvalid_0's auc: 0.735963\n",
      "[71]\tvalid_0's auc: 0.735701\n",
      "[72]\tvalid_0's auc: 0.736101\n",
      "[73]\tvalid_0's auc: 0.736177\n",
      "[74]\tvalid_0's auc: 0.736162\n",
      "[75]\tvalid_0's auc: 0.736467\n",
      "[76]\tvalid_0's auc: 0.736234\n",
      "[77]\tvalid_0's auc: 0.736926\n",
      "[78]\tvalid_0's auc: 0.737262\n",
      "[79]\tvalid_0's auc: 0.737304\n",
      "[80]\tvalid_0's auc: 0.737586\n",
      "[81]\tvalid_0's auc: 0.737756\n",
      "[82]\tvalid_0's auc: 0.737548\n",
      "[83]\tvalid_0's auc: 0.737294\n",
      "[84]\tvalid_0's auc: 0.737488\n",
      "[85]\tvalid_0's auc: 0.737404\n",
      "[86]\tvalid_0's auc: 0.737495\n",
      "[87]\tvalid_0's auc: 0.737523\n",
      "[88]\tvalid_0's auc: 0.737739\n",
      "[89]\tvalid_0's auc: 0.737886\n",
      "[90]\tvalid_0's auc: 0.737822\n",
      "[91]\tvalid_0's auc: 0.73781\n",
      "[92]\tvalid_0's auc: 0.738398\n",
      "[93]\tvalid_0's auc: 0.738657\n",
      "[94]\tvalid_0's auc: 0.738541\n",
      "[95]\tvalid_0's auc: 0.73843\n",
      "[96]\tvalid_0's auc: 0.738347\n",
      "[97]\tvalid_0's auc: 0.738507\n",
      "[98]\tvalid_0's auc: 0.738695\n",
      "[99]\tvalid_0's auc: 0.738794\n",
      "[100]\tvalid_0's auc: 0.738847\n",
      "[101]\tvalid_0's auc: 0.738974\n",
      "[102]\tvalid_0's auc: 0.739016\n",
      "[103]\tvalid_0's auc: 0.738829\n",
      "[104]\tvalid_0's auc: 0.738858\n",
      "[105]\tvalid_0's auc: 0.739103\n",
      "[106]\tvalid_0's auc: 0.739033\n",
      "[107]\tvalid_0's auc: 0.739261\n",
      "[108]\tvalid_0's auc: 0.739402\n",
      "[109]\tvalid_0's auc: 0.739493\n",
      "[110]\tvalid_0's auc: 0.739316\n",
      "[111]\tvalid_0's auc: 0.73916\n",
      "[112]\tvalid_0's auc: 0.739135\n",
      "[113]\tvalid_0's auc: 0.73921\n",
      "[114]\tvalid_0's auc: 0.739199\n",
      "[115]\tvalid_0's auc: 0.739087\n",
      "[116]\tvalid_0's auc: 0.739297\n",
      "[117]\tvalid_0's auc: 0.739488\n",
      "[118]\tvalid_0's auc: 0.739466\n",
      "[119]\tvalid_0's auc: 0.739705\n",
      "[120]\tvalid_0's auc: 0.739974\n",
      "[121]\tvalid_0's auc: 0.739899\n",
      "[122]\tvalid_0's auc: 0.739818\n",
      "[123]\tvalid_0's auc: 0.739858\n",
      "[124]\tvalid_0's auc: 0.739971\n",
      "[125]\tvalid_0's auc: 0.740091\n",
      "[126]\tvalid_0's auc: 0.739938\n",
      "[127]\tvalid_0's auc: 0.739676\n",
      "[128]\tvalid_0's auc: 0.740006\n",
      "[129]\tvalid_0's auc: 0.740018\n",
      "[130]\tvalid_0's auc: 0.740047\n",
      "[131]\tvalid_0's auc: 0.740212\n",
      "[132]\tvalid_0's auc: 0.740496\n",
      "[133]\tvalid_0's auc: 0.740351\n",
      "[134]\tvalid_0's auc: 0.740243\n",
      "[135]\tvalid_0's auc: 0.740234\n",
      "[136]\tvalid_0's auc: 0.740205\n",
      "[137]\tvalid_0's auc: 0.740065\n",
      "[138]\tvalid_0's auc: 0.740098\n",
      "[139]\tvalid_0's auc: 0.740179\n",
      "[140]\tvalid_0's auc: 0.74031\n",
      "[141]\tvalid_0's auc: 0.74033\n",
      "[142]\tvalid_0's auc: 0.740362\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.740496\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.609062\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.631053\n",
      "[3]\tvalid_0's auc: 0.650727\n",
      "[4]\tvalid_0's auc: 0.651491\n",
      "[5]\tvalid_0's auc: 0.676287\n",
      "[6]\tvalid_0's auc: 0.677782\n",
      "[7]\tvalid_0's auc: 0.685866\n",
      "[8]\tvalid_0's auc: 0.693923\n",
      "[9]\tvalid_0's auc: 0.699988\n",
      "[10]\tvalid_0's auc: 0.698736\n",
      "[11]\tvalid_0's auc: 0.696128\n",
      "[12]\tvalid_0's auc: 0.699328\n",
      "[13]\tvalid_0's auc: 0.703872\n",
      "[14]\tvalid_0's auc: 0.702722\n",
      "[15]\tvalid_0's auc: 0.704638\n",
      "[16]\tvalid_0's auc: 0.707586\n",
      "[17]\tvalid_0's auc: 0.708894\n",
      "[18]\tvalid_0's auc: 0.710259\n",
      "[19]\tvalid_0's auc: 0.709471\n",
      "[20]\tvalid_0's auc: 0.71151\n",
      "[21]\tvalid_0's auc: 0.711595\n",
      "[22]\tvalid_0's auc: 0.713116\n",
      "[23]\tvalid_0's auc: 0.713622\n",
      "[24]\tvalid_0's auc: 0.712736\n",
      "[25]\tvalid_0's auc: 0.714248\n",
      "[26]\tvalid_0's auc: 0.714676\n",
      "[27]\tvalid_0's auc: 0.716347\n",
      "[28]\tvalid_0's auc: 0.716671\n",
      "[29]\tvalid_0's auc: 0.716116\n",
      "[30]\tvalid_0's auc: 0.716541\n",
      "[31]\tvalid_0's auc: 0.717089\n",
      "[32]\tvalid_0's auc: 0.71828\n",
      "[33]\tvalid_0's auc: 0.718468\n",
      "[34]\tvalid_0's auc: 0.718684\n",
      "[35]\tvalid_0's auc: 0.718326\n",
      "[36]\tvalid_0's auc: 0.718837\n",
      "[37]\tvalid_0's auc: 0.719003\n",
      "[38]\tvalid_0's auc: 0.720481\n",
      "[39]\tvalid_0's auc: 0.720506\n",
      "[40]\tvalid_0's auc: 0.72076\n",
      "[41]\tvalid_0's auc: 0.721186\n",
      "[42]\tvalid_0's auc: 0.721128\n",
      "[43]\tvalid_0's auc: 0.721404\n",
      "[44]\tvalid_0's auc: 0.721635\n",
      "[45]\tvalid_0's auc: 0.721897\n",
      "[46]\tvalid_0's auc: 0.721975\n",
      "[47]\tvalid_0's auc: 0.722021\n",
      "[48]\tvalid_0's auc: 0.723251\n",
      "[49]\tvalid_0's auc: 0.723402\n",
      "[50]\tvalid_0's auc: 0.723654\n",
      "[51]\tvalid_0's auc: 0.723933\n",
      "[52]\tvalid_0's auc: 0.72392\n",
      "[53]\tvalid_0's auc: 0.724262\n",
      "[54]\tvalid_0's auc: 0.724979\n",
      "[55]\tvalid_0's auc: 0.725049\n",
      "[56]\tvalid_0's auc: 0.725543\n",
      "[57]\tvalid_0's auc: 0.7255\n",
      "[58]\tvalid_0's auc: 0.725661\n",
      "[59]\tvalid_0's auc: 0.725689\n",
      "[60]\tvalid_0's auc: 0.725756\n",
      "[61]\tvalid_0's auc: 0.726103\n",
      "[62]\tvalid_0's auc: 0.725849\n",
      "[63]\tvalid_0's auc: 0.726621\n",
      "[64]\tvalid_0's auc: 0.726504\n",
      "[65]\tvalid_0's auc: 0.726322\n",
      "[66]\tvalid_0's auc: 0.726538\n",
      "[67]\tvalid_0's auc: 0.727037\n",
      "[68]\tvalid_0's auc: 0.727536\n",
      "[69]\tvalid_0's auc: 0.727601\n",
      "[70]\tvalid_0's auc: 0.727764\n",
      "[71]\tvalid_0's auc: 0.728374\n",
      "[72]\tvalid_0's auc: 0.728378\n",
      "[73]\tvalid_0's auc: 0.72862\n",
      "[74]\tvalid_0's auc: 0.728898\n",
      "[75]\tvalid_0's auc: 0.728587\n",
      "[76]\tvalid_0's auc: 0.728616\n",
      "[77]\tvalid_0's auc: 0.72872\n",
      "[78]\tvalid_0's auc: 0.729061\n",
      "[79]\tvalid_0's auc: 0.728859\n",
      "[80]\tvalid_0's auc: 0.728952\n",
      "[81]\tvalid_0's auc: 0.728934\n",
      "[82]\tvalid_0's auc: 0.729147\n",
      "[83]\tvalid_0's auc: 0.729135\n",
      "[84]\tvalid_0's auc: 0.729219\n",
      "[85]\tvalid_0's auc: 0.729604\n",
      "[86]\tvalid_0's auc: 0.729547\n",
      "[87]\tvalid_0's auc: 0.729709\n",
      "[88]\tvalid_0's auc: 0.729657\n",
      "[89]\tvalid_0's auc: 0.72958\n",
      "[90]\tvalid_0's auc: 0.729736\n",
      "[91]\tvalid_0's auc: 0.729836\n",
      "[92]\tvalid_0's auc: 0.730405\n",
      "[93]\tvalid_0's auc: 0.730369\n",
      "[94]\tvalid_0's auc: 0.730874\n",
      "[95]\tvalid_0's auc: 0.73084\n",
      "[96]\tvalid_0's auc: 0.730907\n",
      "[97]\tvalid_0's auc: 0.731043\n",
      "[98]\tvalid_0's auc: 0.731023\n",
      "[99]\tvalid_0's auc: 0.730752\n",
      "[100]\tvalid_0's auc: 0.730636\n",
      "[101]\tvalid_0's auc: 0.730697\n",
      "[102]\tvalid_0's auc: 0.730627\n",
      "[103]\tvalid_0's auc: 0.731215\n",
      "[104]\tvalid_0's auc: 0.731418\n",
      "[105]\tvalid_0's auc: 0.731256\n",
      "[106]\tvalid_0's auc: 0.73131\n",
      "[107]\tvalid_0's auc: 0.731547\n",
      "[108]\tvalid_0's auc: 0.731594\n",
      "[109]\tvalid_0's auc: 0.731815\n",
      "[110]\tvalid_0's auc: 0.731867\n",
      "[111]\tvalid_0's auc: 0.732023\n",
      "[112]\tvalid_0's auc: 0.732183\n",
      "[113]\tvalid_0's auc: 0.732017\n",
      "[114]\tvalid_0's auc: 0.732099\n",
      "[115]\tvalid_0's auc: 0.731977\n",
      "[116]\tvalid_0's auc: 0.732148\n",
      "[117]\tvalid_0's auc: 0.732229\n",
      "[118]\tvalid_0's auc: 0.732183\n",
      "[119]\tvalid_0's auc: 0.732189\n",
      "[120]\tvalid_0's auc: 0.732108\n",
      "[121]\tvalid_0's auc: 0.732053\n",
      "[122]\tvalid_0's auc: 0.732527\n",
      "[123]\tvalid_0's auc: 0.732703\n",
      "[124]\tvalid_0's auc: 0.732881\n",
      "[125]\tvalid_0's auc: 0.732845\n",
      "[126]\tvalid_0's auc: 0.733075\n",
      "[127]\tvalid_0's auc: 0.733156\n",
      "[128]\tvalid_0's auc: 0.733007\n",
      "[129]\tvalid_0's auc: 0.733316\n",
      "[130]\tvalid_0's auc: 0.733244\n",
      "[131]\tvalid_0's auc: 0.733497\n",
      "[132]\tvalid_0's auc: 0.733634\n",
      "[133]\tvalid_0's auc: 0.733622\n",
      "[134]\tvalid_0's auc: 0.73372\n",
      "[135]\tvalid_0's auc: 0.733659\n",
      "[136]\tvalid_0's auc: 0.734039\n",
      "[137]\tvalid_0's auc: 0.734104\n",
      "[138]\tvalid_0's auc: 0.734167\n",
      "[139]\tvalid_0's auc: 0.734308\n",
      "[140]\tvalid_0's auc: 0.734525\n",
      "[141]\tvalid_0's auc: 0.734466\n",
      "[142]\tvalid_0's auc: 0.734536\n",
      "[143]\tvalid_0's auc: 0.734802\n",
      "[144]\tvalid_0's auc: 0.734885\n",
      "[145]\tvalid_0's auc: 0.734742\n",
      "[146]\tvalid_0's auc: 0.73482\n",
      "[147]\tvalid_0's auc: 0.7349\n",
      "[148]\tvalid_0's auc: 0.734901\n",
      "[149]\tvalid_0's auc: 0.734933\n",
      "[150]\tvalid_0's auc: 0.734988\n",
      "[151]\tvalid_0's auc: 0.734928\n",
      "[152]\tvalid_0's auc: 0.734985\n",
      "[153]\tvalid_0's auc: 0.735168\n",
      "[154]\tvalid_0's auc: 0.735222\n",
      "[155]\tvalid_0's auc: 0.735184\n",
      "[156]\tvalid_0's auc: 0.735283\n",
      "[157]\tvalid_0's auc: 0.735188\n",
      "[158]\tvalid_0's auc: 0.735132\n",
      "[159]\tvalid_0's auc: 0.735212\n",
      "[160]\tvalid_0's auc: 0.735179\n",
      "[161]\tvalid_0's auc: 0.735193\n",
      "[162]\tvalid_0's auc: 0.735027\n",
      "[163]\tvalid_0's auc: 0.734938\n",
      "[164]\tvalid_0's auc: 0.735196\n",
      "[165]\tvalid_0's auc: 0.735248\n",
      "[166]\tvalid_0's auc: 0.735206\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's auc: 0.735283\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.605128\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.644356\n",
      "[3]\tvalid_0's auc: 0.666874\n",
      "[4]\tvalid_0's auc: 0.666018\n",
      "[5]\tvalid_0's auc: 0.676432\n",
      "[6]\tvalid_0's auc: 0.675914\n",
      "[7]\tvalid_0's auc: 0.678726\n",
      "[8]\tvalid_0's auc: 0.684425\n",
      "[9]\tvalid_0's auc: 0.698275\n",
      "[10]\tvalid_0's auc: 0.698486\n",
      "[11]\tvalid_0's auc: 0.700503\n",
      "[12]\tvalid_0's auc: 0.702907\n",
      "[13]\tvalid_0's auc: 0.705404\n",
      "[14]\tvalid_0's auc: 0.70583\n",
      "[15]\tvalid_0's auc: 0.705516\n",
      "[16]\tvalid_0's auc: 0.707827\n",
      "[17]\tvalid_0's auc: 0.711485\n",
      "[18]\tvalid_0's auc: 0.71276\n",
      "[19]\tvalid_0's auc: 0.712562\n",
      "[20]\tvalid_0's auc: 0.713435\n",
      "[21]\tvalid_0's auc: 0.714739\n",
      "[22]\tvalid_0's auc: 0.719886\n",
      "[23]\tvalid_0's auc: 0.719811\n",
      "[24]\tvalid_0's auc: 0.720209\n",
      "[25]\tvalid_0's auc: 0.720308\n",
      "[26]\tvalid_0's auc: 0.720307\n",
      "[27]\tvalid_0's auc: 0.721217\n",
      "[28]\tvalid_0's auc: 0.724429\n",
      "[29]\tvalid_0's auc: 0.726047\n",
      "[30]\tvalid_0's auc: 0.727419\n",
      "[31]\tvalid_0's auc: 0.727299\n",
      "[32]\tvalid_0's auc: 0.727591\n",
      "[33]\tvalid_0's auc: 0.728628\n",
      "[34]\tvalid_0's auc: 0.729015\n",
      "[35]\tvalid_0's auc: 0.730967\n",
      "[36]\tvalid_0's auc: 0.730782\n",
      "[37]\tvalid_0's auc: 0.730954\n",
      "[38]\tvalid_0's auc: 0.73082\n",
      "[39]\tvalid_0's auc: 0.731137\n",
      "[40]\tvalid_0's auc: 0.731416\n",
      "[41]\tvalid_0's auc: 0.732777\n",
      "[42]\tvalid_0's auc: 0.733754\n",
      "[43]\tvalid_0's auc: 0.734093\n",
      "[44]\tvalid_0's auc: 0.734125\n",
      "[45]\tvalid_0's auc: 0.735462\n",
      "[46]\tvalid_0's auc: 0.735851\n",
      "[47]\tvalid_0's auc: 0.736412\n",
      "[48]\tvalid_0's auc: 0.737059\n",
      "[49]\tvalid_0's auc: 0.73709\n",
      "[50]\tvalid_0's auc: 0.737042\n",
      "[51]\tvalid_0's auc: 0.737828\n",
      "[52]\tvalid_0's auc: 0.737814\n",
      "[53]\tvalid_0's auc: 0.738403\n",
      "[54]\tvalid_0's auc: 0.73867\n",
      "[55]\tvalid_0's auc: 0.738903\n",
      "[56]\tvalid_0's auc: 0.738989\n",
      "[57]\tvalid_0's auc: 0.739674\n",
      "[58]\tvalid_0's auc: 0.739645\n",
      "[59]\tvalid_0's auc: 0.739773\n",
      "[60]\tvalid_0's auc: 0.740192\n",
      "[61]\tvalid_0's auc: 0.740659\n",
      "[62]\tvalid_0's auc: 0.740505\n",
      "[63]\tvalid_0's auc: 0.74067\n",
      "[64]\tvalid_0's auc: 0.740778\n",
      "[65]\tvalid_0's auc: 0.741815\n",
      "[66]\tvalid_0's auc: 0.741877\n",
      "[67]\tvalid_0's auc: 0.741776\n",
      "[68]\tvalid_0's auc: 0.741679\n",
      "[69]\tvalid_0's auc: 0.742053\n",
      "[70]\tvalid_0's auc: 0.742707\n",
      "[71]\tvalid_0's auc: 0.742704\n",
      "[72]\tvalid_0's auc: 0.743446\n",
      "[73]\tvalid_0's auc: 0.743655\n",
      "[74]\tvalid_0's auc: 0.743799\n",
      "[75]\tvalid_0's auc: 0.74339\n",
      "[76]\tvalid_0's auc: 0.743366\n",
      "[77]\tvalid_0's auc: 0.743464\n",
      "[78]\tvalid_0's auc: 0.743653\n",
      "[79]\tvalid_0's auc: 0.743559\n",
      "[80]\tvalid_0's auc: 0.744094\n",
      "[81]\tvalid_0's auc: 0.744124\n",
      "[82]\tvalid_0's auc: 0.743964\n",
      "[83]\tvalid_0's auc: 0.743943\n",
      "[84]\tvalid_0's auc: 0.743933\n",
      "[85]\tvalid_0's auc: 0.744349\n",
      "[86]\tvalid_0's auc: 0.744304\n",
      "[87]\tvalid_0's auc: 0.744298\n",
      "[88]\tvalid_0's auc: 0.744413\n",
      "[89]\tvalid_0's auc: 0.744893\n",
      "[90]\tvalid_0's auc: 0.744826\n",
      "[91]\tvalid_0's auc: 0.744794\n",
      "[92]\tvalid_0's auc: 0.744907\n",
      "[93]\tvalid_0's auc: 0.745251\n",
      "[94]\tvalid_0's auc: 0.745223\n",
      "[95]\tvalid_0's auc: 0.745136\n",
      "[96]\tvalid_0's auc: 0.745433\n",
      "[97]\tvalid_0's auc: 0.745567\n",
      "[98]\tvalid_0's auc: 0.746012\n",
      "[99]\tvalid_0's auc: 0.745906\n",
      "[100]\tvalid_0's auc: 0.745927\n",
      "[101]\tvalid_0's auc: 0.746263\n",
      "[102]\tvalid_0's auc: 0.74608\n",
      "[103]\tvalid_0's auc: 0.746037\n",
      "[104]\tvalid_0's auc: 0.746251\n",
      "[105]\tvalid_0's auc: 0.746162\n",
      "[106]\tvalid_0's auc: 0.746346\n",
      "[107]\tvalid_0's auc: 0.746623\n",
      "[108]\tvalid_0's auc: 0.746783\n",
      "[109]\tvalid_0's auc: 0.746777\n",
      "[110]\tvalid_0's auc: 0.746975\n",
      "[111]\tvalid_0's auc: 0.747183\n",
      "[112]\tvalid_0's auc: 0.7472\n",
      "[113]\tvalid_0's auc: 0.746902\n",
      "[114]\tvalid_0's auc: 0.747324\n",
      "[115]\tvalid_0's auc: 0.747075\n",
      "[116]\tvalid_0's auc: 0.747008\n",
      "[117]\tvalid_0's auc: 0.74708\n",
      "[118]\tvalid_0's auc: 0.747107\n",
      "[119]\tvalid_0's auc: 0.747186\n",
      "[120]\tvalid_0's auc: 0.747258\n",
      "[121]\tvalid_0's auc: 0.747435\n",
      "[122]\tvalid_0's auc: 0.747525\n",
      "[123]\tvalid_0's auc: 0.74758\n",
      "[124]\tvalid_0's auc: 0.747477\n",
      "[125]\tvalid_0's auc: 0.747695\n",
      "[126]\tvalid_0's auc: 0.747674\n",
      "[127]\tvalid_0's auc: 0.74778\n",
      "[128]\tvalid_0's auc: 0.747865\n",
      "[129]\tvalid_0's auc: 0.747796\n",
      "[130]\tvalid_0's auc: 0.747866\n",
      "[131]\tvalid_0's auc: 0.7479\n",
      "[132]\tvalid_0's auc: 0.748068\n",
      "[133]\tvalid_0's auc: 0.748266\n",
      "[134]\tvalid_0's auc: 0.748058\n",
      "[135]\tvalid_0's auc: 0.74804\n",
      "[136]\tvalid_0's auc: 0.748019\n",
      "[137]\tvalid_0's auc: 0.748083\n",
      "[138]\tvalid_0's auc: 0.74806\n",
      "[139]\tvalid_0's auc: 0.748058\n",
      "[140]\tvalid_0's auc: 0.748258\n",
      "[141]\tvalid_0's auc: 0.748342\n",
      "[142]\tvalid_0's auc: 0.748329\n",
      "[143]\tvalid_0's auc: 0.748447\n",
      "[144]\tvalid_0's auc: 0.7485\n",
      "[145]\tvalid_0's auc: 0.748496\n",
      "[146]\tvalid_0's auc: 0.748466\n",
      "[147]\tvalid_0's auc: 0.748435\n",
      "[148]\tvalid_0's auc: 0.748503\n",
      "[149]\tvalid_0's auc: 0.748467\n",
      "[150]\tvalid_0's auc: 0.748842\n",
      "[151]\tvalid_0's auc: 0.748796\n",
      "[152]\tvalid_0's auc: 0.748826\n",
      "[153]\tvalid_0's auc: 0.748761\n",
      "[154]\tvalid_0's auc: 0.748932\n",
      "[155]\tvalid_0's auc: 0.749056\n",
      "[156]\tvalid_0's auc: 0.749043\n",
      "[157]\tvalid_0's auc: 0.74903\n",
      "[158]\tvalid_0's auc: 0.748921\n",
      "[159]\tvalid_0's auc: 0.748974\n",
      "[160]\tvalid_0's auc: 0.748906\n",
      "[161]\tvalid_0's auc: 0.749071\n",
      "[162]\tvalid_0's auc: 0.749024\n",
      "[163]\tvalid_0's auc: 0.749028\n",
      "[164]\tvalid_0's auc: 0.749169\n",
      "[165]\tvalid_0's auc: 0.749217\n",
      "[166]\tvalid_0's auc: 0.749291\n",
      "[167]\tvalid_0's auc: 0.749266\n",
      "[168]\tvalid_0's auc: 0.749424\n",
      "[169]\tvalid_0's auc: 0.749257\n",
      "[170]\tvalid_0's auc: 0.749163\n",
      "[171]\tvalid_0's auc: 0.749141\n",
      "[172]\tvalid_0's auc: 0.749189\n",
      "[173]\tvalid_0's auc: 0.749239\n",
      "[174]\tvalid_0's auc: 0.749251\n",
      "[175]\tvalid_0's auc: 0.749307\n",
      "[176]\tvalid_0's auc: 0.74922\n",
      "[177]\tvalid_0's auc: 0.749204\n",
      "[178]\tvalid_0's auc: 0.749334\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.749424\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.617091\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.62279\n",
      "[3]\tvalid_0's auc: 0.656802\n",
      "[4]\tvalid_0's auc: 0.684832\n",
      "[5]\tvalid_0's auc: 0.684186\n",
      "[6]\tvalid_0's auc: 0.689764\n",
      "[7]\tvalid_0's auc: 0.694489\n",
      "[8]\tvalid_0's auc: 0.708431\n",
      "[9]\tvalid_0's auc: 0.708175\n",
      "[10]\tvalid_0's auc: 0.705583\n",
      "[11]\tvalid_0's auc: 0.710749\n",
      "[12]\tvalid_0's auc: 0.709451\n",
      "[13]\tvalid_0's auc: 0.710574\n",
      "[14]\tvalid_0's auc: 0.712352\n",
      "[15]\tvalid_0's auc: 0.715209\n",
      "[16]\tvalid_0's auc: 0.7154\n",
      "[17]\tvalid_0's auc: 0.717141\n",
      "[18]\tvalid_0's auc: 0.717924\n",
      "[19]\tvalid_0's auc: 0.720048\n",
      "[20]\tvalid_0's auc: 0.720628\n",
      "[21]\tvalid_0's auc: 0.720835\n",
      "[22]\tvalid_0's auc: 0.724712\n",
      "[23]\tvalid_0's auc: 0.724636\n",
      "[24]\tvalid_0's auc: 0.724974\n",
      "[25]\tvalid_0's auc: 0.725467\n",
      "[26]\tvalid_0's auc: 0.728208\n",
      "[27]\tvalid_0's auc: 0.728873\n",
      "[28]\tvalid_0's auc: 0.728678\n",
      "[29]\tvalid_0's auc: 0.728815\n",
      "[30]\tvalid_0's auc: 0.730081\n",
      "[31]\tvalid_0's auc: 0.729942\n",
      "[32]\tvalid_0's auc: 0.730528\n",
      "[33]\tvalid_0's auc: 0.731356\n",
      "[34]\tvalid_0's auc: 0.731692\n",
      "[35]\tvalid_0's auc: 0.731935\n",
      "[36]\tvalid_0's auc: 0.732283\n",
      "[37]\tvalid_0's auc: 0.73206\n",
      "[38]\tvalid_0's auc: 0.73305\n",
      "[39]\tvalid_0's auc: 0.733579\n",
      "[40]\tvalid_0's auc: 0.733755\n",
      "[41]\tvalid_0's auc: 0.733434\n",
      "[42]\tvalid_0's auc: 0.733738\n",
      "[43]\tvalid_0's auc: 0.734114\n",
      "[44]\tvalid_0's auc: 0.734511\n",
      "[45]\tvalid_0's auc: 0.734845\n",
      "[46]\tvalid_0's auc: 0.734816\n",
      "[47]\tvalid_0's auc: 0.734889\n",
      "[48]\tvalid_0's auc: 0.734982\n",
      "[49]\tvalid_0's auc: 0.735777\n",
      "[50]\tvalid_0's auc: 0.736673\n",
      "[51]\tvalid_0's auc: 0.736584\n",
      "[52]\tvalid_0's auc: 0.736738\n",
      "[53]\tvalid_0's auc: 0.736953\n",
      "[54]\tvalid_0's auc: 0.737026\n",
      "[55]\tvalid_0's auc: 0.737763\n",
      "[56]\tvalid_0's auc: 0.738451\n",
      "[57]\tvalid_0's auc: 0.738433\n",
      "[58]\tvalid_0's auc: 0.73865\n",
      "[59]\tvalid_0's auc: 0.73883\n",
      "[60]\tvalid_0's auc: 0.739201\n",
      "[61]\tvalid_0's auc: 0.73934\n",
      "[62]\tvalid_0's auc: 0.739614\n",
      "[63]\tvalid_0's auc: 0.739798\n",
      "[64]\tvalid_0's auc: 0.739927\n",
      "[65]\tvalid_0's auc: 0.740355\n",
      "[66]\tvalid_0's auc: 0.740561\n",
      "[67]\tvalid_0's auc: 0.740696\n",
      "[68]\tvalid_0's auc: 0.740991\n",
      "[69]\tvalid_0's auc: 0.741169\n",
      "[70]\tvalid_0's auc: 0.74113\n",
      "[71]\tvalid_0's auc: 0.741381\n",
      "[72]\tvalid_0's auc: 0.741246\n",
      "[73]\tvalid_0's auc: 0.741832\n",
      "[74]\tvalid_0's auc: 0.741858\n",
      "[75]\tvalid_0's auc: 0.741855\n",
      "[76]\tvalid_0's auc: 0.742075\n",
      "[77]\tvalid_0's auc: 0.742074\n",
      "[78]\tvalid_0's auc: 0.742127\n",
      "[79]\tvalid_0's auc: 0.741998\n",
      "[80]\tvalid_0's auc: 0.742107\n",
      "[81]\tvalid_0's auc: 0.742067\n",
      "[82]\tvalid_0's auc: 0.742185\n",
      "[83]\tvalid_0's auc: 0.742252\n",
      "[84]\tvalid_0's auc: 0.74229\n",
      "[85]\tvalid_0's auc: 0.742508\n",
      "[86]\tvalid_0's auc: 0.742766\n",
      "[87]\tvalid_0's auc: 0.742804\n",
      "[88]\tvalid_0's auc: 0.742624\n",
      "[89]\tvalid_0's auc: 0.742626\n",
      "[90]\tvalid_0's auc: 0.742429\n",
      "[91]\tvalid_0's auc: 0.742563\n",
      "[92]\tvalid_0's auc: 0.742456\n",
      "[93]\tvalid_0's auc: 0.742459\n",
      "[94]\tvalid_0's auc: 0.742621\n",
      "[95]\tvalid_0's auc: 0.742819\n",
      "[96]\tvalid_0's auc: 0.742805\n",
      "[97]\tvalid_0's auc: 0.742863\n",
      "[98]\tvalid_0's auc: 0.74298\n",
      "[99]\tvalid_0's auc: 0.742908\n",
      "[100]\tvalid_0's auc: 0.743145\n",
      "[101]\tvalid_0's auc: 0.743099\n",
      "[102]\tvalid_0's auc: 0.74321\n",
      "[103]\tvalid_0's auc: 0.743352\n",
      "[104]\tvalid_0's auc: 0.7431\n",
      "[105]\tvalid_0's auc: 0.743336\n",
      "[106]\tvalid_0's auc: 0.743533\n",
      "[107]\tvalid_0's auc: 0.743622\n",
      "[108]\tvalid_0's auc: 0.743561\n",
      "[109]\tvalid_0's auc: 0.743802\n",
      "[110]\tvalid_0's auc: 0.743927\n",
      "[111]\tvalid_0's auc: 0.743944\n",
      "[112]\tvalid_0's auc: 0.743995\n",
      "[113]\tvalid_0's auc: 0.743942\n",
      "[114]\tvalid_0's auc: 0.744062\n",
      "[115]\tvalid_0's auc: 0.744171\n",
      "[116]\tvalid_0's auc: 0.744092\n",
      "[117]\tvalid_0's auc: 0.74434\n",
      "[118]\tvalid_0's auc: 0.744362\n",
      "[119]\tvalid_0's auc: 0.744361\n",
      "[120]\tvalid_0's auc: 0.744166\n",
      "[121]\tvalid_0's auc: 0.744225\n",
      "[122]\tvalid_0's auc: 0.744102\n",
      "[123]\tvalid_0's auc: 0.744098\n",
      "[124]\tvalid_0's auc: 0.744208\n",
      "[125]\tvalid_0's auc: 0.744284\n",
      "[126]\tvalid_0's auc: 0.744291\n",
      "[127]\tvalid_0's auc: 0.744236\n",
      "[128]\tvalid_0's auc: 0.74418\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's auc: 0.744362\n",
      "[ 2938 15428 10749 ...  2093 15930 13693]\n",
      "[LightGBM] [Info] Number of positive: 6392, number of negative: 6392\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 12784, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[1]\tvalid_0's auc: 0.616421\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.643758\n",
      "[3]\tvalid_0's auc: 0.648835\n",
      "[4]\tvalid_0's auc: 0.657864\n",
      "[5]\tvalid_0's auc: 0.674531\n",
      "[6]\tvalid_0's auc: 0.677425\n",
      "[7]\tvalid_0's auc: 0.704528\n",
      "[8]\tvalid_0's auc: 0.703248\n",
      "[9]\tvalid_0's auc: 0.70131\n",
      "[10]\tvalid_0's auc: 0.703395\n",
      "[11]\tvalid_0's auc: 0.70714\n",
      "[12]\tvalid_0's auc: 0.706452\n",
      "[13]\tvalid_0's auc: 0.705548\n",
      "[14]\tvalid_0's auc: 0.71218\n",
      "[15]\tvalid_0's auc: 0.714203\n",
      "[16]\tvalid_0's auc: 0.715874\n",
      "[17]\tvalid_0's auc: 0.716438\n",
      "[18]\tvalid_0's auc: 0.719978\n",
      "[19]\tvalid_0's auc: 0.720002\n",
      "[20]\tvalid_0's auc: 0.721135\n",
      "[21]\tvalid_0's auc: 0.723029\n",
      "[22]\tvalid_0's auc: 0.724071\n",
      "[23]\tvalid_0's auc: 0.724755\n",
      "[24]\tvalid_0's auc: 0.725107\n",
      "[25]\tvalid_0's auc: 0.726162\n",
      "[26]\tvalid_0's auc: 0.72826\n",
      "[27]\tvalid_0's auc: 0.729\n",
      "[28]\tvalid_0's auc: 0.728343\n",
      "[29]\tvalid_0's auc: 0.727828\n",
      "[30]\tvalid_0's auc: 0.728528\n",
      "[31]\tvalid_0's auc: 0.729182\n",
      "[32]\tvalid_0's auc: 0.730019\n",
      "[33]\tvalid_0's auc: 0.730288\n",
      "[34]\tvalid_0's auc: 0.730798\n",
      "[35]\tvalid_0's auc: 0.730569\n",
      "[36]\tvalid_0's auc: 0.731335\n",
      "[37]\tvalid_0's auc: 0.731398\n",
      "[38]\tvalid_0's auc: 0.731617\n",
      "[39]\tvalid_0's auc: 0.73148\n",
      "[40]\tvalid_0's auc: 0.731968\n",
      "[41]\tvalid_0's auc: 0.731891\n",
      "[42]\tvalid_0's auc: 0.732617\n",
      "[43]\tvalid_0's auc: 0.732895\n",
      "[44]\tvalid_0's auc: 0.733006\n",
      "[45]\tvalid_0's auc: 0.733001\n",
      "[46]\tvalid_0's auc: 0.733116\n",
      "[47]\tvalid_0's auc: 0.733495\n",
      "[48]\tvalid_0's auc: 0.733669\n",
      "[49]\tvalid_0's auc: 0.734281\n",
      "[50]\tvalid_0's auc: 0.733873\n",
      "[51]\tvalid_0's auc: 0.734129\n",
      "[52]\tvalid_0's auc: 0.734499\n",
      "[53]\tvalid_0's auc: 0.734267\n",
      "[54]\tvalid_0's auc: 0.734125\n",
      "[55]\tvalid_0's auc: 0.734749\n",
      "[56]\tvalid_0's auc: 0.734942\n",
      "[57]\tvalid_0's auc: 0.735119\n",
      "[58]\tvalid_0's auc: 0.735351\n",
      "[59]\tvalid_0's auc: 0.735536\n",
      "[60]\tvalid_0's auc: 0.735229\n",
      "[61]\tvalid_0's auc: 0.735204\n",
      "[62]\tvalid_0's auc: 0.735197\n",
      "[63]\tvalid_0's auc: 0.736275\n",
      "[64]\tvalid_0's auc: 0.736562\n",
      "[65]\tvalid_0's auc: 0.736907\n",
      "[66]\tvalid_0's auc: 0.736874\n",
      "[67]\tvalid_0's auc: 0.737257\n",
      "[68]\tvalid_0's auc: 0.737266\n",
      "[69]\tvalid_0's auc: 0.737249\n",
      "[70]\tvalid_0's auc: 0.737193\n",
      "[71]\tvalid_0's auc: 0.737359\n",
      "[72]\tvalid_0's auc: 0.737442\n",
      "[73]\tvalid_0's auc: 0.737676\n",
      "[74]\tvalid_0's auc: 0.737757\n",
      "[75]\tvalid_0's auc: 0.737742\n",
      "[76]\tvalid_0's auc: 0.737981\n",
      "[77]\tvalid_0's auc: 0.738461\n",
      "[78]\tvalid_0's auc: 0.738496\n",
      "[79]\tvalid_0's auc: 0.73846\n",
      "[80]\tvalid_0's auc: 0.73826\n",
      "[81]\tvalid_0's auc: 0.738341\n",
      "[82]\tvalid_0's auc: 0.738615\n",
      "[83]\tvalid_0's auc: 0.738449\n",
      "[84]\tvalid_0's auc: 0.738495\n",
      "[85]\tvalid_0's auc: 0.738564\n",
      "[86]\tvalid_0's auc: 0.738521\n",
      "[87]\tvalid_0's auc: 0.738445\n",
      "[88]\tvalid_0's auc: 0.738511\n",
      "[89]\tvalid_0's auc: 0.73867\n",
      "[90]\tvalid_0's auc: 0.738723\n",
      "[91]\tvalid_0's auc: 0.738642\n",
      "[92]\tvalid_0's auc: 0.738587\n",
      "[93]\tvalid_0's auc: 0.738381\n",
      "[94]\tvalid_0's auc: 0.738934\n",
      "[95]\tvalid_0's auc: 0.739138\n",
      "[96]\tvalid_0's auc: 0.739863\n",
      "[97]\tvalid_0's auc: 0.740273\n",
      "[98]\tvalid_0's auc: 0.740195\n",
      "[99]\tvalid_0's auc: 0.74018\n",
      "[100]\tvalid_0's auc: 0.740288\n",
      "[101]\tvalid_0's auc: 0.7403\n",
      "[102]\tvalid_0's auc: 0.740407\n",
      "[103]\tvalid_0's auc: 0.740561\n",
      "[104]\tvalid_0's auc: 0.740547\n",
      "[105]\tvalid_0's auc: 0.740711\n",
      "[106]\tvalid_0's auc: 0.741072\n",
      "[107]\tvalid_0's auc: 0.741649\n",
      "[108]\tvalid_0's auc: 0.741434\n",
      "[109]\tvalid_0's auc: 0.741478\n",
      "[110]\tvalid_0's auc: 0.741885\n",
      "[111]\tvalid_0's auc: 0.742146\n",
      "[112]\tvalid_0's auc: 0.742087\n",
      "[113]\tvalid_0's auc: 0.742008\n",
      "[114]\tvalid_0's auc: 0.74194\n",
      "[115]\tvalid_0's auc: 0.74205\n",
      "[116]\tvalid_0's auc: 0.742078\n",
      "[117]\tvalid_0's auc: 0.741965\n",
      "[118]\tvalid_0's auc: 0.741837\n",
      "[119]\tvalid_0's auc: 0.742053\n",
      "[120]\tvalid_0's auc: 0.742108\n",
      "[121]\tvalid_0's auc: 0.742032\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.742146\n",
      "CPU times: user 3.84 s, sys: 114 ms, total: 3.95 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = []\n",
    "\n",
    "for i in range(10):\n",
    "    models.append(bagging(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7256719557019524\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "\n",
    "for m in models:\n",
    "    y_preds.append(m.predict(X_test, num_iteration=m.best_iteration))\n",
    "\n",
    "y_preds_bagging = sum(y_preds)/len(y_preds)\n",
    "# auc を計算する\n",
    "auc = roc_auc_score(y_test, y_preds_bagging)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.6714643304130162\n",
      "roc_auc_score: 0.7308891668402775\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train2,y_train2 )\n",
    "y_pred_prob = clf.predict_proba(X_valid)[:,1]\n",
    "y_pred_prob = clf.predict_proba(X_valid)[:,1]\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_prob]\n",
    "print(f'accuracy_score: {accuracy_score(y_valid, y_pred)}')\n",
    "print(f'roc_auc_score: {roc_auc_score(y_valid, y_pred_prob)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
